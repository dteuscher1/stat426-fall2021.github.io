<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2021-12-09T14:55:07-07:00</updated><id>/feed.xml</id><title type="html">Stat 426 - Fall 2021</title><subtitle>Class Blog and Projects</subtitle><entry><title type="html">Top 10 Skills a future Data Scientist should learn while their machine is also learning.</title><link href="/blog/top-10-skills" rel="alternate" type="text/html" title="Top 10 Skills a future Data Scientist should learn while their machine is also learning." /><published>2021-11-22T00:00:00-07:00</published><updated>2021-11-22T00:00:00-07:00</updated><id>/blog/top-10-skills</id><content type="html" xml:base="/blog/top-10-skills">&lt;h2 id=&quot;intro&quot;&gt;Intro:&lt;/h2&gt;

&lt;p&gt;You are sitting in the chair at your desk, about to train a model so that you can use it to make predictions on your current data. However as soon as you run the code, you discover that it isn’t going to take as fast as you thought it was going to take. Instead of waiting 15 seconds, you will have to wait 5 minutes. The best thing to do to avoid this situation in the future is to upgrade your computer. However, not everyone has the time or the money to do so. Therefore the second best thing is to use this time while your machine is learning to learn how to become a better data scientist. As such, here are the Top 10 Skills a data scientist should know.&lt;/p&gt;

&lt;h2 id=&quot;skill-1-being-curious&quot;&gt;Skill 1: Being Curious&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-22/skill1.jpg&quot; alt=&quot;Skill 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The most important skill in being an effective data scientist isn’t actually about the field data science itself. It’s about the tendency to ask questions relentlessly. A successful data scientist isn’t someone who looks at data and doesn’t know what to say. Instead they are very curious to understand what the data is actually saying and also if it can answer questions that haven’t been asked in the first place. Therefore the most important skill in becoming a successful data scientist is being curious and always wondering about why it works the way that it works.&lt;/p&gt;

&lt;h2 id=&quot;skill-2-understanding-statistics&quot;&gt;Skill 2: Understanding Statistics&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-22/skill2.png&quot; alt=&quot;Skill 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;However, just being able to ask intellectual questions isn’t very helpful if you don’t understand how to find the answers. Therefore just like coding, another skill a data scientist should have is an understanding of probability and statistics and also the best way to apply what you have learned. Often times a simple understanding of statistics is not enough and effective data scientists have to have a solid understanding of statistics so that they are able to come up with a better model or algorithm that can describe the data more clearly&lt;/p&gt;

&lt;h2 id=&quot;skill-3-communicating-with-your-machine&quot;&gt;Skill 3: Communicating with your machine&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-22/skill3.jpg&quot; alt=&quot;Skill 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can be one of the smartest mathematicians or understand the theory of probability really well, however if you don’t understand how to communicate with your machine and tell it what you want it to do, you aren’t going to get far in the data science world. This is because although you can come up with an impressive algorithm, if you aren’t able to write it in a language that a machine can understand you are then obviously unable to use thar algorithm. This is where knowledge of common data science languages such as Python, SQL or R is a necessity. Because machines aren’t able to make decisions on their own, we have to tell them what they need to do.&lt;/p&gt;

&lt;h2 id=&quot;skill-4-manipulating-data&quot;&gt;Skill 4: Manipulating data.&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-22/skill4.png&quot; alt=&quot;Skill 4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Another skill a data scientist should have is knowing how to prepare their data so that they are more easily able to draw conclusions from it. Majority of the data that data scientists receive isn’t very nice or  beautiful to look at. A lot of times the data is very unorganized and therefore in this current situation it is nearly impossible to draw conclusions and to discover and answer questions. Therefore an effective data scientist knows how to take any dataset and make it so that it is way easier to work with. Although this does not seem like that much of an important skill in data science, it is one of the most important skills because without it, the job of data scientist becomes much harder, nearly impossible.&lt;/p&gt;

&lt;h2 id=&quot;skill-5-exploring-the-data&quot;&gt;Skill 5 Exploring the Data&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-22/skill5.png&quot; alt=&quot;Skill 5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is also one of the most important skills that a data scientist should know. However it is also one of the hardest and most time consuming but also very rewarding in the end. This is because it takes a lot of patience and intelligence to draw conclusions from the data. An effective data scientist is someone who, when given tons of data, is then able to come to the company with an answer to questions that the company doesn’t even have. Therefore this skill goes hand in hand with the being curious skill because if you aren’t curious you will be unable to find concessions between the variables in the data.&lt;/p&gt;

&lt;h2 id=&quot;skill-6-machine-learning&quot;&gt;Skill 6: Machine Learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-22/skill6.jpeg&quot; alt=&quot;Skill 6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For some reason there are many data scientists that don’t know much about machine learning. This is partly because it is somewhat of a new field and therefore not many people see the necessity of it. However machine learning techniques can put you ahead of the competition and make you very marketable. Therefore you should know techniques such as
factorization machines, clustering, decision trees, deep learning, optimization, neural  networks and their frameworks such as spark and tensorflow.&lt;/p&gt;

&lt;h2 id=&quot;skill-7-using-big-data&quot;&gt;Skill 7: Using big data&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-22/skill7.jpg&quot; alt=&quot;Skill 7&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaking of which, this leads us to another skill that data scientists should know which is the use of big data. This is because in the past decade the creation, capturing, copying, and consumption of data went up by a whopping 5000%. As such the data sets that are used today aren’t as simple as the datasets back then. Instead of a few tables with a few variables in each there are multiple tables with each table having multiple variables that somehow relate to each other. Therefore to develop insights from these types of data, data scientists should have a solid understanding of the most popular big data sets that are used.&lt;/p&gt;

&lt;h2 id=&quot;skill-8-knowledge-of-business&quot;&gt;Skill 8: Knowledge of Business.&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-22/skill8.jpg&quot; alt=&quot;Skill 8&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The understanding of how business works is very essential in becoming a good data scientist. Because a data scientist who understands business then is able to understand the benefit that his/her finding has for the overall organization zigon of a whole. It is now not much about completing a task that was assigned but understanding the importance of the task and the role it has to the entire company.&lt;/p&gt;

&lt;h2 id=&quot;skill-9-data-visualization&quot;&gt;Skill 9: Data Visualization&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-22/skill9.jpg&quot; alt=&quot;Skill 9&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Another important skill in becoming a data scientist is knowing how to present your data in a way that can help you describe to others your findings. This is when you have to figure out what way your data should be presented. Therefore you should have a solid understanding of different kinds of charts such as histograms, bar graphs, pie charts and also advanced charts such as waterfall charts. Also being able to plot functions on these charts is very useful. Not only does doing so make the next skill a lot easier, it also makes exploring your data easier as well.&lt;/p&gt;

&lt;h2 id=&quot;skill-10-communicating-with-others&quot;&gt;Skill 10: Communicating with others&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-22/skill10.jpg&quot; alt=&quot;Skill 10&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Finally a very good skill that a data scientist should have is to be very effective in communication. Although you can find very valuable connections between variables if you aren’t able to communicate it to others in an effective way then it would be hard for others to understand your discoveries. That is why a data scientist should also work on his/her communication skills because it isn’t the machine that does the communication for them, it is them.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Now you see why the Data Science Career is a very rewarding but also very difficult career to have. This is because the best data scientists are people who are very good at math, statistics, developing models but also very good at implementing models and drawing conclusions based on what they were given. However if you are able to learn the majority of the above skills you will be way ahead of the competition. Therefore although you’re not prolly going to be paid to develop these skills they will still make you a better data scientist overall.&lt;/p&gt;

&lt;h3 id=&quot;helpful-links&quot;&gt;Helpful Links&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Skill 3: &lt;a href=&quot;https://www.linkedin.com/learning/topics/python?accountId=2153100&amp;amp;u=2153100&amp;amp;success=true&amp;amp;authUUID=E%2BagPUnkQpCaU2Ws9EcJTA%3D%3D&quot;&gt;LinkedIn Python&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Skill 4: &lt;a href=&quot;https://www.datacamp.com/community/tutorials/web-scraping-using-python&quot;&gt;Web Scraping&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Skill 5: &lt;a href=&quot;https://www.listendata.com/2014/06/data-exploration-using-r.html&quot;&gt;Exploring the Data with R&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Skill 6: &lt;a href=&quot;https://www.mathworks.com/solutions/machine-learning/tutorials-examples.html?ef_id=CjwKCAiAv_KMBhAzEiwAs-rX1KcRG_OT51NYkQ0O7H4J7zE1rMJprL_OtC0pqfRPWafjpFTU2qHrMhoChsYQAvD_BwE:G:s&amp;amp;s_kwcid=AL!8664!3!521120568225!p!!g!!machine%20learning%20tutorial&amp;amp;s_eid=psn_57384016232&amp;amp;q=machine%20learning%20tutorial&amp;amp;gclid=CjwKCAiAv_KMBhAzEiwAs-rX1KcRG_OT51NYkQ0O7H4J7zE1rMJprL_OtC0pqfRPWafjpFTU2qHrMhoChsYQAvD_BwE&quot;&gt;Machine Learning with R&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Skill 7: &lt;a href=&quot;https://www.udemy.com/course/big-data-and-hadoop-essentials-free-tutorial/&quot;&gt;Hadoop Tutorial&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Skill 9: &lt;a href=&quot;https://flowingdata.com/category/tutorials/&quot;&gt;Data Visualization Tutorials&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Gavin Williams</name><email>gmw72718@gmail.com</email></author><category term="Big Data" /><category term="Data Science" /><category term="Top 10 Skills" /><category term="Machine Learning" /><summary type="html">Intro:</summary></entry><entry><title type="html">REVIEW: INVISIBLE WOMEN. EXPOSING DATA BIAS IN A WORLD DESIGNED BY MEN, BY CAROLINE CRIADO PEREZ</title><link href="/blog/gender-data-gap" rel="alternate" type="text/html" title="REVIEW: INVISIBLE WOMEN. EXPOSING DATA BIAS IN A WORLD DESIGNED BY MEN, BY CAROLINE CRIADO PEREZ" /><published>2021-11-19T00:00:00-07:00</published><updated>2021-11-19T00:00:00-07:00</updated><id>/blog/gender-data-gap</id><content type="html" xml:base="/blog/gender-data-gap">&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-28/cover.jpg&quot; alt=&quot;Book-Cover&quot; /&gt;&lt;/p&gt;

&lt;p&gt;“One of the most important things to say about the gender data gap is that it is not generally malicious, or even deliberate. Quite the opposite. It is simply the product of a way of thinking that has been around for millennia and is therefore a kind of not thinking. A double not thinking, even: men go without saying, and women don’t get said at all. Because when we say human, on the whole, we mean man.”
      ― Caroline Criado Perez&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;If you have ever felt confused when people talk about white male privilege but aren’t interested in op-ed pieces, or if you are curious about the role data plays in sexism but don’t know where to start, this is the book for you! Caroline Criado-Perez, author, provides detailed and well-researched examples in every sphere to demonstrate the gender data gap and why it matters.&lt;/p&gt;

&lt;h2 id=&quot;what-is-the-gender-data-gap&quot;&gt;What is the Gender Data Gap?&lt;/h2&gt;

&lt;p&gt;The gender data gap is the fact that the majority of data we have in the world is based around the male body and the typical male life pattern. Data is fundamental to our world today.  We are dependent on data to make decisions in every aspect of life; health care, education, transportation, workplace and more.  But if the data isn’t representative of the population or if the data isn’t aggregated by gender, the results are biased.&lt;/p&gt;

&lt;h2 id=&quot;what-does-it-look-like&quot;&gt;What does it look like?&lt;/h2&gt;

&lt;p&gt;Criado Perez gives example after example ranging from slightly annoying (women freezing in their offices because temperatures are adjusted for the higher metabolic rate of men), to deadly (women being more 17% more likely to be killed in car collisions because male dummies are used for safety testing) making it clear to see just how ubiquitous gender data bias is.
Another example is with research on heart attacks.  Much of the research on heart attacks has focused on men. This has led to a life-threatening gender data gap because roughly two thirds of women experience less-typical symptoms.  A British cardiology study revealed that women experience 50% higher rates of heart attack misdiagnosis with fewer women surviving the first attack.
One of the most alarming examples from this book was about medical research. Women are routinely excluded from clinical trials even though sex differences are found in every single organ and tissue and in the prevalence, course and severity of most common diseases.  Diseases that only affect women (ex. Pre-menstrual syndrome) are consistently under-studied, whereas male specific diseases have significantly more funding and research.  Even when women are included in clinical trials, data is rarely sex-aggregated which makes determining different responses between male and female impossible to determine. A pain medication that doesn’t work for men, may work great for women but without aggregating the data, you’d never know.&lt;/p&gt;

&lt;h2 id=&quot;why-should-we-care&quot;&gt;Why should we care?&lt;/h2&gt;

&lt;p&gt;Unrepresentative data leads to bad results and conclusions. Data feeds into algorithms and hardware that turn into products and solutions that systematically favor half the population. Hardware, such as phone sizes or shelf heights, are simpler to fix.  Algorithms are more difficult. As future data scientists and statisticians it is important to understand the flaws and consequences of the way things are done now so we can make more informed decisions when we have more influence. Part of data science education is understanding the implications that limited perspectives and biases of have on society.&lt;/p&gt;

&lt;h2 id=&quot;what-can-be-done&quot;&gt;What can be done?&lt;/h2&gt;

&lt;p&gt;This book doesn’t try to explain why the gender data gap exists or who is to blame, it simply lays out data-backed examples to illustrate that the problem exists and that education on the issue and more diversity can alleviate the problem.&lt;br /&gt;
Here is one example of how diversity can help with the gender data gap. Gyms, parks and sports grounds are typically male dominated.  Officials chalk this up to a difference in preferences between men and women. Recent studies show that when men and women’s preferences are accounted for in the design of these spaces, they are equally used between genders. Diversity is essential in groups of decision makers.  Many of the gender data bias is not due to explicit sexism, it is because the people in the room making the decisions are male, and either assume that female needs are the same as theirs, or they fail to remember women’s needs at all.  This applies to racial minorities and other marginalized groups.  The more perspectives are involved in planning, the less likely it is that bias will continue.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I would highly recommend this book to everyone, men and women.  It has helped me see things through a new lense.  The book is full of Criado Perez’s humor and wit but is all very data driven so it isn’t just her opinions, she drives her point with facts.  In a world that is more and more data-driven, these types of conversations need to be had.  It is the way to make the world a more comfortable place for women and other groups that are routinely overlooked.  This book challenges the reader to take a step outside their own perspective and think about ways biased data presents itself in society.  Besides the examples given in this blogpost, where have you seen the gender data gap?&lt;/p&gt;

&lt;p&gt;This book can be purchased &lt;a href=&quot;https://www.amazon.com/Invisible-Women-Data-World-Designed/dp/1419729071&quot;&gt;here&lt;/a&gt;&lt;/p&gt;</content><author><name>Maddie Hays</name><email>madeleinehays7@gmail.com</email></author><category term="Book Review" /><category term="Data Science" /><category term="Statistics" /><category term="Feminism" /><summary type="html"></summary></entry><entry><title type="html">What Coding Language Should I Learn?</title><link href="/blog/coding-languages" rel="alternate" type="text/html" title="What Coding Language Should I Learn?" /><published>2021-11-17T00:00:00-07:00</published><updated>2021-11-17T00:00:00-07:00</updated><id>/blog/coding-languages</id><content type="html" xml:base="/blog/coding-languages">&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;p&gt;I want to be a data analyst, which coding language should I learn? What if I want to be a business analyst, does that make a difference? Can I just learn one language or do I need to be able to write code for multiple platforms? Based on my own experience applying for jobs, there are many different coding languages that people can learn, but not all are used on a regular basis. Here are some of those languages and platforms that might help you get a head start in the world of data.&lt;/p&gt;

&lt;h2 id=&quot;is-there-one-language-to-rule-them-all&quot;&gt;Is there one language to rule them all?&lt;/h2&gt;

&lt;p&gt;The short answer to all of these questions is start with Python. In my experience applying to jobs as well as viewing data and reading articles all over the internet, this seems to be the language that everyone wants to use. Python is extremely versatile due to the fact that it is open source and already has one of the largest databases of packages. If you can’t find a package that suits your needs, you can always create your own. Python is also one of the easiest coding languages to learn. Because of that it is the language of choice for many companies, which means you see it in a lot of job descriptions.&lt;/p&gt;

&lt;p&gt;Using Python checks all the boxes as far as analyzing data goes. You can read in data from just about anywhere or from any format and convert it to whatever you’d like. You can clean it relatively simply. There are also packages that allow you to run and manipulate statistical models without doing it all from scratch. Then you can predict future values based on the data. Finally, there are also many packages dedicated to data visualization. This final point is key because you have to be able to show people what you have done in a way that is easily readable and readily available. Not every coding language out there has the number of features that Python does when it comes to creating charts and graphs. They range from simple line graphs and scatter plots to pie charts and even multi-dimensional graphs.&lt;/p&gt;

&lt;p&gt;Another advantage to learning Python is that it can be used as the backbone for many websites and applications. This isn’t something that will interest everyone or even be of use to most people. However, if software engineering or building websites sounds appealing, I would look into this a little bit more. There are design spaces dedicated to building applications and websites using only Python code and it works quite well. In fact, bigger companies like Google, or Meta (once Facebook) use it in some applications like YouTube and Instagram on the backend because it is that powerful and easy to work with.&lt;/p&gt;

&lt;p&gt;Example graphs:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-17/python_example_3.png&quot; alt=&quot;Basic Graph&quot; /&gt;   &lt;img src=&quot;/assets/images/blogimages/figs-11-17/python_example_1.jpg&quot; alt=&quot;3D Graph&quot; /&gt;    &lt;img src=&quot;/assets/images/blogimages/figs-11-17/python_example_2.jpg&quot; alt=&quot;Color Coded Graph&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-next-best-thing&quot;&gt;The next best thing&lt;/h2&gt;

&lt;p&gt;Python is awesome but that doesn’t mean it is the only coding language out there worth looking at. R is the coding language that was built specifically for data analysts. R is the place to be for statistics and numbers. You can do a lot of the same stuff with Python, but R is the specialized language for statisticians and is therefore a little more intuitive for those in a statistics background. Larger datasets are also going to be more better suited for R, especially when using RStudio. R has a very large amount of packages (called libraries in R) which allow you to read, write, manipulate and visualize data with just a few keystrokes in many cases.&lt;/p&gt;

&lt;p&gt;Even though R isn’t built for creating web applications like Python is, you can use R Shiny for building interactive databases that allow people to do some of the manipulating or graphing with a few clicks in their browser. This is a great option for when the needs of the client are always changing or they need a lot of different graphs more than once.&lt;/p&gt;

&lt;p&gt;Here is an example of R code that adds numbers:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; x
[1]  2 NA  3  1  4
&amp;gt; sum(x)    # if any element is NA or NaN, result is NA or NaN
[1] NA
&amp;gt; sum(x, na.rm=TRUE)    # this way we can ignore NA and NaN values
[1] 10

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;the-database-code&quot;&gt;The database code&lt;/h2&gt;

&lt;p&gt;SQL is the structured query language. This language is built for a very specific purpose, which is communicating with, searching in and extracting data from databases. Many databases contain millions of rows of data which means it isn’t easy to sort through it all when you’re looking for something specific. That’s where SQL comes in handy. You can sort through all of that data to pull out just what you need for the project you’re working on. One of the other great things about this language is that you can call it inside other languages. For example, you can write Python code to read in and manipulate the data, but you find the correct data by writing your own SQL query. An example is below. There are a few more steps than this, but I am just trying to show you that it is possible to write it inside other languages.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import sqlite3
import pandas as pd

#This is the SQL code to select all rows from the factbook dataset
query = &quot;SELECT * FROM factbook;&quot;
sql_connect = sqlite3.connect('factbook.db')
pd.read_sql_query(query,sql_connect)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;the-data-visualization-languages&quot;&gt;The data visualization languages&lt;/h2&gt;

&lt;p&gt;Python and R do pretty well when it comes to data visualization and there are many ways you can show off your data through these two. However, there are some specialized platforms that allow you to get even more out of your graphs. In my experience there are two main platforms that stand out and are asked for often. These are Tableau and Power BI. With these platforms you can take data visualization to a whole new level. Tableau is built for the ease of use when you try and show off a dataset for a presentation. Power BI is a little more specialized because it allows other people to go in and pull the reports that you have written up for just one department or date range depending on the needs of that specific person.&lt;/p&gt;

&lt;p&gt;According to what I have seen, these platforms aren’t always something that companies care to see that you have experience in, but for those that generally work with clients and need to show their work to others that don’t know the data side of things this is a popular way to go.&lt;/p&gt;

&lt;p&gt;Example of what Tableau can do:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-17/tableau_example.png&quot; alt=&quot;Tableau&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Example of Power BI:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-17/powerbi_example.jpg&quot; alt=&quot;Power BI&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-one-you-didnt-expect&quot;&gt;The one you didn’t expect&lt;/h2&gt;

&lt;p&gt;The final language I recommend you look into is Excel. I know what you’re thinking, “This isn’t a coding language. I can’t do any of the bigger picture stuff with Excel.”. In general, you would be right, but there are many cases where this is very important. Excel usually just displays data in columns and rows for you to be able to see it all in one place, but there is a background language in there called VBA (Visual Basic for Applications). This is where you can write code to manipulate the cells and data in the worksheets to be what you need. Using Excel isn’t something that would be used all the time, but many companies that store data in Excel spreadsheets would require you to know more advanced techniques in Excel.&lt;/p&gt;

&lt;p&gt;VBA allows you to pull in data from databases using SQL as well as Microsoft Access, among others. Then you use VBA to write code that manipulates that data into something that everyone viewing the worksheet can utilize in their day to day work. You can write code to create graphs, fill in the blanks, sort and filter data based on user input, add on to the data based on user input and check that it’s valid, and so much more. The best part is that you can write this code and someone who knows nothing about Excel can go in, hit a button or start typing and everything you wrote in VBA starts up and allows them to do everything they need.&lt;/p&gt;

&lt;p&gt;A lot about coding in Excel VBA isn’t about modeling data or even data visualization (although it could be), it’s about making sure everyone else that uses this same spreadsheet can input correct data and then press a button (or do nothing) and have everything get sorted, cleaned, manipulated, and even graphed exactly how they need it without ever having to learn to code themselves. This is the best suited for a business analyst because the end user would be within the company.&lt;/p&gt;

&lt;p&gt;Here is an example of VBA where the user hits the button ‘Roll’ and the code runs in order to randomize the letters on the game board:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-17/excel_vba_example.jpg&quot; alt=&quot;Excel VBA&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The list I have here isn’t a perfect list of coding languages that everyone should learn. Out there in the real world, there are many other languages and platforms that you could learn in order to help out a company in your role as an analyst. I have found that these ones often come up in job applications as popular choices for companies to work with. There isn’t just one language to rule them all because they all have their strengths. If you are just starting out, I would say start exploring Python because that is the most versatile and generally the easiest. If you are more advanced and have specific needs based on your interests or current job, look into something like Tableau for data visualization or Excel to help others handle their data needs. Regardless of where you are in your education though, more languages exist to help you accomplish the goals of your company or client so don’t stop at these 6, keep learning and find the one(s) that fit your needs the best.&lt;/p&gt;

&lt;h3 id=&quot;learn-more&quot;&gt;Learn More&lt;/h3&gt;

&lt;p&gt;Python: (https://www.python.org/doc/essays/blurb/)&lt;/p&gt;

&lt;p&gt;R: (https://www.r-project.org/)&lt;/p&gt;

&lt;p&gt;SQL: (https://www.w3schools.com/sql/sql_intro.asp)&lt;/p&gt;

&lt;p&gt;Tableau: (https://www.tableau.com)&lt;/p&gt;

&lt;p&gt;Power BI: (https://powerbi.microsoft.com/en-us/)&lt;/p&gt;

&lt;p&gt;Excel VBA: (https://docs.microsoft.com/en-us/office/vba/library-reference/concepts/getting-started-with-vba-in-office)&lt;/p&gt;</content><author><name>Nicholas Austill</name><email>nmaustill@gmail.com</email></author><category term="Python" /><category term="Learn to code" /><category term="R" /><category term="Tableau" /><category term="Excel" /><summary type="html">Intro I want to be a data analyst, which coding language should I learn? What if I want to be a business analyst, does that make a difference? Can I just learn one language or do I need to be able to write code for multiple platforms? Based on my own experience applying for jobs, there are many different coding languages that people can learn, but not all are used on a regular basis. Here are some of those languages and platforms that might help you get a head start in the world of data. Is there one language to rule them all? The short answer to all of these questions is start with Python. In my experience applying to jobs as well as viewing data and reading articles all over the internet, this seems to be the language that everyone wants to use. Python is extremely versatile due to the fact that it is open source and already has one of the largest databases of packages. If you can’t find a package that suits your needs, you can always create your own. Python is also one of the easiest coding languages to learn. Because of that it is the language of choice for many companies, which means you see it in a lot of job descriptions. Using Python checks all the boxes as far as analyzing data goes. You can read in data from just about anywhere or from any format and convert it to whatever you’d like. You can clean it relatively simply. There are also packages that allow you to run and manipulate statistical models without doing it all from scratch. Then you can predict future values based on the data. Finally, there are also many packages dedicated to data visualization. This final point is key because you have to be able to show people what you have done in a way that is easily readable and readily available. Not every coding language out there has the number of features that Python does when it comes to creating charts and graphs. They range from simple line graphs and scatter plots to pie charts and even multi-dimensional graphs. Another advantage to learning Python is that it can be used as the backbone for many websites and applications. This isn’t something that will interest everyone or even be of use to most people. However, if software engineering or building websites sounds appealing, I would look into this a little bit more. There are design spaces dedicated to building applications and websites using only Python code and it works quite well. In fact, bigger companies like Google, or Meta (once Facebook) use it in some applications like YouTube and Instagram on the backend because it is that powerful and easy to work with. Example graphs: The next best thing Python is awesome but that doesn’t mean it is the only coding language out there worth looking at. R is the coding language that was built specifically for data analysts. R is the place to be for statistics and numbers. You can do a lot of the same stuff with Python, but R is the specialized language for statisticians and is therefore a little more intuitive for those in a statistics background. Larger datasets are also going to be more better suited for R, especially when using RStudio. R has a very large amount of packages (called libraries in R) which allow you to read, write, manipulate and visualize data with just a few keystrokes in many cases. Even though R isn’t built for creating web applications like Python is, you can use R Shiny for building interactive databases that allow people to do some of the manipulating or graphing with a few clicks in their browser. This is a great option for when the needs of the client are always changing or they need a lot of different graphs more than once. Here is an example of R code that adds numbers: &amp;gt; x [1] 2 NA 3 1 4 &amp;gt; sum(x) # if any element is NA or NaN, result is NA or NaN [1] NA &amp;gt; sum(x, na.rm=TRUE) # this way we can ignore NA and NaN values [1] 10 The database code SQL is the structured query language. This language is built for a very specific purpose, which is communicating with, searching in and extracting data from databases. Many databases contain millions of rows of data which means it isn’t easy to sort through it all when you’re looking for something specific. That’s where SQL comes in handy. You can sort through all of that data to pull out just what you need for the project you’re working on. One of the other great things about this language is that you can call it inside other languages. For example, you can write Python code to read in and manipulate the data, but you find the correct data by writing your own SQL query. An example is below. There are a few more steps than this, but I am just trying to show you that it is possible to write it inside other languages. import sqlite3 import pandas as pd #This is the SQL code to select all rows from the factbook dataset query = &quot;SELECT * FROM factbook;&quot; sql_connect = sqlite3.connect('factbook.db') pd.read_sql_query(query,sql_connect) The data visualization languages Python and R do pretty well when it comes to data visualization and there are many ways you can show off your data through these two. However, there are some specialized platforms that allow you to get even more out of your graphs. In my experience there are two main platforms that stand out and are asked for often. These are Tableau and Power BI. With these platforms you can take data visualization to a whole new level. Tableau is built for the ease of use when you try and show off a dataset for a presentation. Power BI is a little more specialized because it allows other people to go in and pull the reports that you have written up for just one department or date range depending on the needs of that specific person. According to what I have seen, these platforms aren’t always something that companies care to see that you have experience in, but for those that generally work with clients and need to show their work to others that don’t know the data side of things this is a popular way to go. Example of what Tableau can do: Example of Power BI: The one you didn’t expect The final language I recommend you look into is Excel. I know what you’re thinking, “This isn’t a coding language. I can’t do any of the bigger picture stuff with Excel.”. In general, you would be right, but there are many cases where this is very important. Excel usually just displays data in columns and rows for you to be able to see it all in one place, but there is a background language in there called VBA (Visual Basic for Applications). This is where you can write code to manipulate the cells and data in the worksheets to be what you need. Using Excel isn’t something that would be used all the time, but many companies that store data in Excel spreadsheets would require you to know more advanced techniques in Excel. VBA allows you to pull in data from databases using SQL as well as Microsoft Access, among others. Then you use VBA to write code that manipulates that data into something that everyone viewing the worksheet can utilize in their day to day work. You can write code to create graphs, fill in the blanks, sort and filter data based on user input, add on to the data based on user input and check that it’s valid, and so much more. The best part is that you can write this code and someone who knows nothing about Excel can go in, hit a button or start typing and everything you wrote in VBA starts up and allows them to do everything they need. A lot about coding in Excel VBA isn’t about modeling data or even data visualization (although it could be), it’s about making sure everyone else that uses this same spreadsheet can input correct data and then press a button (or do nothing) and have everything get sorted, cleaned, manipulated, and even graphed exactly how they need it without ever having to learn to code themselves. This is the best suited for a business analyst because the end user would be within the company. Here is an example of VBA where the user hits the button ‘Roll’ and the code runs in order to randomize the letters on the game board: Conclusion The list I have here isn’t a perfect list of coding languages that everyone should learn. Out there in the real world, there are many other languages and platforms that you could learn in order to help out a company in your role as an analyst. I have found that these ones often come up in job applications as popular choices for companies to work with. There isn’t just one language to rule them all because they all have their strengths. If you are just starting out, I would say start exploring Python because that is the most versatile and generally the easiest. If you are more advanced and have specific needs based on your interests or current job, look into something like Tableau for data visualization or Excel to help others handle their data needs. Regardless of where you are in your education though, more languages exist to help you accomplish the goals of your company or client so don’t stop at these 6, keep learning and find the one(s) that fit your needs the best. Learn More Python: (https://www.python.org/doc/essays/blurb/) R: (https://www.r-project.org/) SQL: (https://www.w3schools.com/sql/sql_intro.asp) Tableau: (https://www.tableau.com) Power BI: (https://powerbi.microsoft.com/en-us/) Excel VBA: (https://docs.microsoft.com/en-us/office/vba/library-reference/concepts/getting-started-with-vba-in-office)</summary></entry><entry><title type="html">Lies Damn Lies and Statistics: A Review of Darrell Huff’s Book How to Lie With Statistics</title><link href="/blog/lying-with-statistics" rel="alternate" type="text/html" title="Lies Damn Lies and Statistics: A Review of Darrell Huff’s Book How to Lie With Statistics" /><published>2021-11-16T00:00:00-07:00</published><updated>2021-11-16T00:00:00-07:00</updated><id>/blog/lying-with-statistics</id><content type="html" xml:base="/blog/lying-with-statistics">&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-16/Book-Cover-Image.jpg&quot; alt=&quot;Book-Cover&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;As data becomes more prevalent, the ability to correctly interpret that data becomes more crucial. This is particularly true when, either nefariously or out of ignorance, some individuals or organizations report data in a way that misrepresents what it says. In Darrell Huff’s book, &lt;em&gt;&lt;a href=&quot;https://www.amazon.com/How-Lie-Statistics-Darrell-Huff/dp/0393310728&quot;&gt;How to Lie with Statistics&lt;/a&gt;&lt;/em&gt;, Huff discusses nine common ways in which people misrepresent data through statistics and or graphs. This review covers five of the most common ways and how to best identify and react to these misrepresentations.&lt;/p&gt;

&lt;h1 id=&quot;samples-with-built-in-bias&quot;&gt;Samples with Built-in Bias&lt;/h1&gt;

&lt;p&gt;The first question Huff has us ask of a statistic is how the data was gathered that led to that statistic. Huff gives the example of a survey in which graduates from Yale University were asked what their current annual income was. This question has bias because people making more money may be more likely to report their salary, while those not making their desired income may not report or may over report their actually salary. Certain questions come with inherit bias. To make matters worse, the group being surveyed can carry similar bias. If we go to a university and ask how many people suffer from back pain, their answers will not be an accurate representation of the number of cases of back pain for a more general population. When collecting data we must consider whether the question or the group being surveyed introduces bias to the data.&lt;/p&gt;

&lt;h1 id=&quot;unreported-figures&quot;&gt;Unreported figures&lt;/h1&gt;

&lt;p&gt;Many reported figures lack important information that make the figure misleading. Two examples of this are not disclosing range of data or the survey sample size. An example of the problem of not showing the range of the data is if you are simply told the average summer sales representative makes $10,000 a summer without the information that one representative made $505,000 while the other ninety-nine all made $5,000 each, then you might misguidedly forego an guaranteed $9,000 internship. Similarly, not knowing the sample size behind a statistic can mislead. For example, if a test compares two cough medicines and one relieves coughs in five out of the ten people and the other relieves coughs in four out of five people, the 30% difference seems large until you know too few people were tested. When viewing data-based figure, it is important to recognize that unreported figures might change one’s conclusion.&lt;/p&gt;

&lt;h1 id=&quot;comparing-apples-to-almost-apples&quot;&gt;Comparing Apples to Almost Apples&lt;/h1&gt;

&lt;p&gt;Sometimes people report statistics comparing unlike groups as if they were more alike than they actually are. An example Huff uses in &lt;em&gt;How to Lie with Statistics&lt;/em&gt; is the reported death rates during the Spanish American war. The Navy recruiting station reported that only nine in every one thousand sailors died compared to sixteen in every one thousand civilians living in New York City. This presentation makes signing up for war with the Navy feel safe, until you consider that the New York City death rate included death due to old age, infant deaths, and those already suffering from aliments. With this additional information, the Navy doesn’t seem quite as safe as presented. We must be vigilant in ensuring that the groups being compared are actually alike.&lt;/p&gt;

&lt;h1 id=&quot;graphs&quot;&gt;Graphs&lt;/h1&gt;

&lt;p&gt;The media is filled with graphs and charts trying to convey information in an intuitive and easy to digest way. However, some of these easy to read graphs can be misleading. Such graphs prey on those who take the chart at face value. One of the most common ways in which graphs take advantage of the unassuming consumer is to truncate the y axis of a graph. If we look at the plot of the left, it appears as though horror movies make substantially more money that action movies. It is only when we take a closer look that we see there is a much smaller difference (see plot of the right). In fact, there is only a 5% difference between money made in each movie genre. People also apply this trick by changing the x axis. Having unequal spaces between observations can cause havoc when it comes to graph interpretation. Special care must be taken when looking at graphs, like looking at the x and y axis and considering the units being expressed on each.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-16/Movie-Plot-Truncated.png&quot; width=&quot;400&quot; /&gt; &lt;img src=&quot;/assets/images/blogimages/figs-11-16/Movie-Plot.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;correlation-doesnt-mean-causation&quot;&gt;Correlation Doesn’t Mean Causation&lt;/h1&gt;

&lt;p&gt;Perhaps the most common deception in statistical reporting is inferring that one outcome &lt;em&gt;caused&lt;/em&gt; the other when in fact there is only a &lt;em&gt;correlation&lt;/em&gt;. An exaggerated example of this type of thinking might be seen in ice cream sales and crime rates. Often as the sales of ice cream rise so do crime rates. Does that mean police should be sent out to impound all ice cream trucks? Obviously not. There might be other factors that cause both ice cream and crime to rise at the same time – like hot summer weather. Another example Huff touches on in his book is the correlation between students who drink and smoke and getting bad grades. One might assume that students get bad grades because they drink and smoke, but it is also probable that students who get bad grades are driven to smoking and drinking to cope with the stress. We are often too quick to draw a causal relationship between to variables without first putting in the work to create a test in which all variables can be controlled for in some way.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This post only covers a few ways in which statistics and graphs can be misleading. Huff suggests several questions to help identify many misleading numbers.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Who says so?&lt;/li&gt;
  &lt;li&gt;How do they know?&lt;/li&gt;
  &lt;li&gt;What’s missing?&lt;/li&gt;
  &lt;li&gt;Did someone change the subject?&lt;/li&gt;
  &lt;li&gt;Does it make sense?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When it comes to interpreting numbers and data, it is important to slow down and think about what has led to this number that we are now seeing. When we do this, we can often avoid making rash decisions on numbers that don’t really mean anything or don’t mean what is being sugested. So the next time you see a staistic, take a minute to really think about what it is saying and if there might be any ulterior motives.&lt;/p&gt;

&lt;p&gt;If you are looking for examples of the misleading use of statistics, there is no better place than a &lt;a href=&quot;https://www.reddit.com/r/badstats/&quot;&gt;reddit forum&lt;/a&gt;.&lt;/p&gt;</content><author><name>Sam Johnson</name><email>smbjohnson98@gmail.com</email></author><category term="Book Review" /><category term="Data Science" /><category term="Statistics" /><category term="Data Literacy" /><category term="Darrell Huff" /><summary type="html"></summary></entry><entry><title type="html">How to scrape song lyrics in R: a webscraper for beginners</title><link href="/blog/lyric-scraper" rel="alternate" type="text/html" title="How to scrape song lyrics in R: a webscraper for beginners" /><published>2021-11-15T00:00:00-07:00</published><updated>2021-11-15T00:00:00-07:00</updated><id>/blog/lyric-scraper</id><content type="html" xml:base="/blog/lyric-scraper">&lt;h1 id=&quot;how-to-scrape-song-lyrics-in-r-a-webscraper-for-beginners&quot;&gt;How to scrape song lyrics in R: a webscraper for beginners&lt;/h1&gt;

&lt;p&gt;Words are data, and some of the most influential words in pop culture are song lyrics.  In order to conduct any sort of word analysis, first you need the words to the song.&lt;/p&gt;

&lt;p&gt;Luckily for us, azlyrics.com has an extremely organized and simple structure for all of their song lyric code on their webpage. Take a minute to observe the pattern of code for “Love Story” by Taylor Swift.&lt;/p&gt;

&lt;p&gt;Note: You can view this same code by going to this url (https://www.azlyrics.com/lyrics/taylorswift/lovestory.html) and pressing Ctrl + u.  A new tab will open showing the html code for the website. The lyrics start around line 150.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;&amp;lt;b&amp;gt;&quot;Love Story&quot;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;

&amp;lt;div&amp;gt;
&amp;lt;!-- Usage of azlyrics.com content by any third-party lyrics provider is prohibited by our licensing agreement. Sorry about that. --&amp;gt;
We were both young when I first saw you&amp;lt;br&amp;gt;
I close my eyes and the flashback starts:&amp;lt;br&amp;gt;
I'm standing there&amp;lt;br&amp;gt;
On a balcony in summer air&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
See the lights, see the party, the ball gowns&amp;lt;br&amp;gt;
See you make your way through the crowd&amp;lt;br&amp;gt;
And say, &amp;amp;quot;Hello.&amp;amp;quot;&amp;lt;br&amp;gt;
Little did I know&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
That you were Romeo, you were throwing pebbles&amp;lt;br&amp;gt;
And my daddy said, &amp;amp;quot;Stay away from Juliet.&amp;amp;quot;&amp;lt;br&amp;gt;
And I was crying on the staircase&amp;lt;br&amp;gt;
Begging you, &amp;amp;quot;Please don't go.&amp;amp;quot;&amp;lt;br&amp;gt;
And I said&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
&amp;amp;quot;Romeo, take me somewhere we can be alone&amp;lt;br&amp;gt;
I'll be waiting. All there's left to do is run&amp;lt;br&amp;gt;
You'll be the prince and I'll be the princess&amp;lt;br&amp;gt;
It's a love story. Baby, just say 'Yes'.&amp;amp;quot;&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
So, I sneak out to the garden to see you&amp;lt;br&amp;gt;
We keep quiet 'cause we're dead if they knew&amp;lt;br&amp;gt;
So, close your eyes&amp;lt;br&amp;gt;
Escape this town for a little while&amp;lt;br&amp;gt;
Oh, oh&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
'Cause you were Romeo. I was a scarlet letter&amp;lt;br&amp;gt;
And my daddy said, &amp;amp;quot;Stay away from Juliet.&amp;amp;quot;&amp;lt;br&amp;gt;
But you were everything to me&amp;lt;br&amp;gt;
I was begging you, &amp;amp;quot;Please don't go!&amp;amp;quot;&amp;lt;br&amp;gt;
And I said&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
&amp;amp;quot;Romeo, take me somewhere we can be alone&amp;lt;br&amp;gt;
I'll be waiting. All there's left to do is run&amp;lt;br&amp;gt;
You'll be the prince and I'll be the princess&amp;lt;br&amp;gt;
It's a love story. Baby, just say 'Yes'&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
Romeo, save me. They're trying to tell me how to feel&amp;lt;br&amp;gt;
This love is difficult but it's real&amp;lt;br&amp;gt;
Don't be afraid. We'll make it out of this mess&amp;lt;br&amp;gt;
It's a love story. Baby, just say 'Yes'.&amp;amp;quot;&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
Oh, oh, oh&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
I got tired of waiting&amp;lt;br&amp;gt;
Wondering if you were ever coming around&amp;lt;br&amp;gt;
My faith in you was fading&amp;lt;br&amp;gt;
When I met you on the outskirts of town&amp;lt;br&amp;gt;
And I said&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
&amp;amp;quot;Romeo, save me. I've been feeling so alone&amp;lt;br&amp;gt;
I keep waiting for you, but you never come&amp;lt;br&amp;gt;
Is this in my head? I don't know what to think.&amp;amp;quot;&amp;lt;br&amp;gt;
He knelt to the ground and pulled out a ring and said&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
&amp;amp;quot;Marry me, Juliet. You'll never have to be alone&amp;lt;br&amp;gt;
I love you, and that's all I really know&amp;lt;br&amp;gt;
I talked to your dad. Go pick out a white dress&amp;lt;br&amp;gt;
It's a love story. Baby, just say 'Yes'.&amp;amp;quot;&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
Oh, oh, oh, oh, oh, oh&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
'Cause we were both young when I first saw you
&amp;lt;/div&amp;gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because of its consistency, we will be able to create a scraper that outputs lyrics for any song / artist combination that’s listed on their website.  Here’s how to make a beginning web scraper scrape any song lyrics you’d like:&lt;/p&gt;

&lt;h3 id=&quot;step-1&quot;&gt;Step 1&lt;/h3&gt;

&lt;p&gt;First, lets import the tidyverse.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;library(tidyverse)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;step-2&quot;&gt;Step 2&lt;/h3&gt;

&lt;p&gt;We need to find a way to produce the song’s unique url on azlyrics.com using only the artist name and song title.&lt;/p&gt;

&lt;p&gt;The urls on AZlyrics.com have a very specific pattern to them.  They look like this:&lt;/p&gt;

&lt;p&gt;https://www.azlyrics.com/lyrics/taylorswift/backtodecember.html&lt;/p&gt;

&lt;p&gt;https://www.azlyrics.com/lyrics/edsheeran/shapeofyou.html&lt;/p&gt;

&lt;p&gt;https://www.azlyrics.com/lyrics/adele/easyonme.html&lt;/p&gt;

&lt;p&gt;Notice the pattern?  Because AZlyrics has a distinct pattern for their URL, we can generate unique web lyric pages easily with just an artist name and song title.&lt;/p&gt;

&lt;p&gt;https://www.azlyrics.com/lyrics/ + artist + / + song + .html&lt;/p&gt;

&lt;p&gt;Which we can paste together like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;artist &amp;lt;- &quot;taylorswift&quot;
song &amp;lt;- &quot;lovestory&quot;

my_url &amp;lt;- str_c(&quot;https://azlyrics.com/lyrics/&quot;, artist, &quot;/&quot;, song, &quot;.html&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;step-3&quot;&gt;Step 3&lt;/h3&gt;

&lt;p&gt;Next, we need to pick where to start scraping.  In this case, every page of html code on AZlyrics contains “prohibited by our licensing agreement. Sorry about that.” on the line before the lyrics begin.  We will use this to show the scraper where to start scraping, and title it our “giveaway”.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;giveaway &amp;lt;- &quot;prohibited by our licensing agreement. Sorry about that.&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Also, note that every page of code marks the end of the lyrics with “&amp;lt;/div&amp;gt;”.  We will use this in our final code to show the scraper where to stop scraping from.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;# get starting line
start &amp;lt;- grep(giveaway, read_lines(my_url)) + 1 # start at line after giveaway

# get ending line
end &amp;lt;- grep(&quot;&amp;lt;/div&amp;gt;&quot;, read_lines(my_url)[start:length(read_lines(my_url))])[1] + start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;step-4&quot;&gt;Step 4&lt;/h3&gt;

&lt;p&gt;Last, we use all the pieces we have put together so far to read each line of lyrics from start to end, and paste them all together.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;paste(gsub(&quot;&amp;lt;br&amp;gt;|&amp;lt;/div&amp;gt;&quot;, &quot;&quot;, read_lines(my_url)[start:end]), collapse = &quot; &quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;putting-it-all-together&quot;&gt;Putting it all together&lt;/h3&gt;

&lt;p&gt;Here is the complete function that will get lyrics for any song:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;# Function to get lyrics from any artist
getlyrics &amp;lt;- function(artist, song){
  giveaway &amp;lt;- &quot;prohibited by our licensing agreement. Sorry about that.&quot;
  my_url &amp;lt;- str_c(&quot;https://azlyrics.com/lyrics/&quot;, artist, &quot;/&quot;, song, &quot;.html&quot;)
  start &amp;lt;- grep(giveaway, read_lines(my_url)) + 1 # start at line after giveaway
  end &amp;lt;- grep(&quot;&amp;lt;/div&amp;gt;&quot;, read_lines(my_url)[start:length(read_lines(my_url))])[1] + start
  paste(gsub(&quot;&amp;lt;br&amp;gt;|&amp;lt;/div&amp;gt;&quot;, &quot;&quot;, read_lines(my_url)[start:end]), collapse = &quot; &quot;)
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now all we have to do whenever we want song lyrics is input an artist name and song title into our function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;getlyrics(&quot;taylorswift&quot;, &quot;lovestory&quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Gives the following output:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{r echo=TRUE}
 [1] &quot;We were both young when I first saw you&quot;              
 [2] &quot;I close my eyes and the flashback starts:&quot;            
 [3] &quot;I'm standing there&quot;                                   
 [4] &quot;On a balcony in summer air&quot;                           
 [5] &quot;&quot;                                                     
 [6] &quot;See the lights, see the party, the ball gowns&quot;        
 [7] &quot;See you make your way through the crowd&quot;              
 [8] &quot;And say, &amp;amp;quot;Hello.&amp;amp;quot;&quot;                          
 [9] &quot;Little did I know&quot;                                    
[10] &quot;&quot;                                                     
[11] &quot;That you were Romeo, you were throwing pebbles&quot;       
[12] &quot;And my daddy said, &amp;amp;quot;Stay away from Juliet.&amp;amp;quot;&quot;
[13] &quot;And I was crying on the staircase&quot;                    
[14] &quot;Begging you, &amp;amp;quot;Please don't go.&amp;amp;quot;&quot;            
[15] &quot;And I said&quot;                                           
[16] &quot;&quot;                                                     
[17] &quot;&amp;amp;quot;Romeo, take me somewhere we can be alone&quot;       
[18] &quot;I'll be waiting. All there's left to do is run&quot;       
[19] &quot;You'll be the prince and I'll be the princess&quot;        
[20] &quot;It's a love story. Baby, just say 'Yes'.&amp;amp;quot;&quot;
[21] &quot;&quot;                                                     
[22] &quot;So, I sneak out to the garden to see you&quot;             
[23] &quot;We keep quiet 'cause we're dead if they knew&quot;         
[24] &quot;So, close your eyes&quot;                                  
[25] &quot;Escape this town for a little while&quot;                  
[26] &quot;Oh, oh&quot;                                               
[27] &quot;&quot;                                                     
[28] &quot;'Cause you were Romeo. I was a scarlet letter&quot;        
[29] &quot;And my daddy said, &amp;amp;quot;Stay away from Juliet.&amp;amp;quot;&quot;
[30] &quot;But you were everything to me&quot;                        
[31] &quot;I was begging you, &amp;amp;quot;Please don't go!&amp;amp;quot;&quot;      
[32] &quot;And I said&quot;                                           
[33] &quot;&quot;                                                     
[34] &quot;&amp;amp;quot;Romeo, take me somewhere we can be alone&quot;       
[35] &quot;I'll be waiting. All there's left to do is run&quot;       
[36] &quot;You'll be the prince and I'll be the princess&quot;        
[37] &quot;It's a love story. Baby, just say 'Yes'&quot;              
[38] &quot;&quot;                                                     
[39] &quot;Romeo, save me. They're trying to tell me how to feel&quot;
[40] &quot;This love is difficult but it's real&quot;                 
[41] &quot;Don't be afraid. We'll make it out of this mess&quot;      
[42] &quot;It's a love story. Baby, just say 'Yes'.&amp;amp;quot;&quot;       
[43] &quot;&quot;                                                     
[44] &quot;Oh, oh, oh&quot;                                           
[45] &quot;&quot;                                                     
[46] &quot;I got tired of waiting&quot;                               
[47] &quot;Wondering if you were ever coming around&quot;             
[48] &quot;My faith in you was fading&quot;
[49] &quot;When I met you on the outskirts of town&quot;              
[50] &quot;And I said&quot;                                           
[51] &quot;&quot;                                                     
[52] &quot;&amp;amp;quot;Romeo, save me. I've been feeling so alone&quot;     
[53] &quot;I keep waiting for you, but you never come&quot;           
[54] &quot;Is this in my head? I don't know what to think.&amp;amp;quot;&quot;
[55] &quot;He knelt to the ground and pulled out a ring and said&quot;
[56] &quot;&quot;                                                     
[57] &quot;&amp;amp;quot;Marry me, Juliet. You'll never have to be alone&quot;
[58] &quot;I love you, and that's all I really know&quot;             
[59] &quot;I talked to your dad. Go pick out a white dress&quot;      
[60] &quot;It's a love story. Baby, just say 'Yes'.&amp;amp;quot;&quot;       
[61] &quot;&quot;                                                     
[62] &quot;Oh, oh, oh, oh, oh, oh&quot;                               
[63] &quot;&quot;                                                     
[64] &quot;'Cause we were both young when I first saw you&quot;
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Note: In order to create the correct url, all artist names and song titles must be all lowercase and not contain spaces.  For example, instead of “Taylor Swift” we will input “taylorswift” as our artist.  We could easily write code to fix this as a next step, but for now our scraper is working just fine for a beginner web scraper.&lt;/p&gt;

&lt;p&gt;Note:  When using this scraper on a large scale, I have occasionally been temporarily blocked from scraping on the azlyrics website.  In my experience this has only happened when looping through many songs, and I regain access within a few hours.&lt;/p&gt;</content><author><name>Rachel Hamilton</name><email>rachelhamilton47@gmail.com</email></author><category term="webscraping" /><category term="lyrics" /><category term="tutorial" /><summary type="html">How to scrape song lyrics in R: a webscraper for beginners</summary></entry><entry><title type="html">Non-Parametric Tests: Statistically Efficient or Technically Cheating?</title><link href="/blog/Non-Parametric-Tests" rel="alternate" type="text/html" title="Non-Parametric Tests: Statistically Efficient or Technically Cheating?" /><published>2021-11-13T00:00:00-07:00</published><updated>2021-11-13T00:00:00-07:00</updated><id>/blog/Non-Parametric%20Tests</id><content type="html" xml:base="/blog/Non-Parametric-Tests">&lt;h1 id=&quot;non-parametric-tests-statistically-efficient-or-technically-cheating&quot;&gt;Non-Parametric Tests: Statistically Efficient or Technically Cheating?&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/xLgsGZV/Frank-Wilcoxon.png&quot; alt=&quot;This is an image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Tired of memorizing countless distributions and their parameters? Well, you’re in luck, because through non-parametric tests, you can run all of the same types of tests that you learned in your former statistics courses without worrying about distributions or parameters. Not only that, but, as it turns out, a lot of the data that we encounter in the real world is not normally distributed, which makes non-parametric tests that much more useful.&lt;/p&gt;

&lt;h2 id=&quot;so-what-are-they&quot;&gt;So What Are They?&lt;/h2&gt;
&lt;p&gt;In statistics, non-parametric tests are methods of statistical analysis that do not require a distribution to meet the required assumptions to be analyzed. For this reason, they are sometimes referred to as distribution-free tests. Nonparametric tests serve as an alternative to parametric tests such as a t-test or ANOVA which can only be employed if the data satisfies certain specific assumptions. Although using non-parametric tests results in losing power if the data is normally distributed, if the data is not normally distributed, using non-parametric tests will almost always be more powerful than using parametric tests.&lt;/p&gt;

&lt;h2 id=&quot;specifically-when-to-use-them&quot;&gt;Specifically When to Use Them&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Data does not meet the assumptions about the population sample&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Generally, the application of parametric tests requires various assumptions to be satisfied. Some of them include the data following a normal distribution and the population variance being homogeneous. However, many datasets are not like this. Sometimes, the dataset might be skewed.The skewness makes the parametric tests less powerful because the mean is no longer the best measure of central tendency because it is strongly affected by the extreme values. However, nonparametric tests work well with skewed distributions and distributions that are better represented by the median.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;The population sample size is too small&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The sample size is an important assumption in selecting the appropriate statistical method. If a sample size is reasonably large, the applicable parametric test can be used. However, if a sample size is too small, it is possible that you may not be able to validate the distribution of the data. Thus, the application of nonparametric tests is the only suitable option.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;The analyzed data is ordinal or nominal&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Unlike parametric tests that can work only with continuous data, nonparametric tests can be applied to other data types such as ordinal or nominal data. For such types of variables, the nonparametric tests are the only appropriate solution.&lt;/p&gt;
&lt;h2 id=&quot;types-of-tests&quot;&gt;Types of Tests&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn.corporatefinanceinstitute.com/assets/nonparametric-tests.png&quot; alt=&quot;image.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Mann-Whitney U Test&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Mann-Whitney U Test is a non-parametric version of the independent samples t-test. The test primarily deals with two independent samples that contain ordinal data. Like the t-test, it is used to test whether two samples are likely to derive from the same population. Unlike its parametric brother, however, the Mann-Whitney U test bases its outcomes on rank, not raw numbers. This makes the test more robust, as it would not be affected by outliers as much as the t-test.&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;The Kruskal-Wallis Test&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Kruskal-Wallis test, proposed by Kruskal and Wallis in 1952, is a nonparametric method for testing whether samples are originated from the same distribution. It works in a similar way to the Mann-Whitney U test, except it uses more than two groups. The null hypothesis of the Kruskal-Wallis test is that the mean ranks of the groups are the same, while the alternative hypothesis is that at least one of the mena ranks is different. It is the nonparametric equivalent one-way ANOVA, but unlike the one-way ANOVA, the nonparametric Kruskal-Wallis test does not assume a normal distribution of the underlying data.&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;p&gt;Enough talk, lets try to understand non-parametric tests through an actual example. Let’s use an easy and clear dataset to demonstrate a particular type of non-parametric test, the Mann-Whitney U Test. We will compare the number of accidents caused by distracted driving and drinking and driving in Utah from 2010 to 2020,&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; and we will be using R throughout the entire process, so you can do it yourself when this is all done.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;EDA&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Distracted &amp;lt;- c(4267,4363,4667,5138,5581,5816,5831,5825,5772,5601,4801)
Alcohol &amp;lt;- c(1633,1406,1572,1624,1700,1883,1925,1825,1915,1923,1971)
year &amp;lt;- c(2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020)

Utah_crash &amp;lt;-data.frame(Distracted, Alcohol, year)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/58bzRTj/EDA.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As we can clearly see, distracted driving causes many more accidents. We probably don’t even need any type of formal test to prove that there is a statistically significant difference, but, again, we are using an easy example to see how non-parametric tests work.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hist(Utah_crash$Distracted, main = &quot;Distracted Driving&quot;, xlab= &quot;Number of Crashes&quot;)
hist(Utah_crash$Alcohol, main = &quot;Drinking and Driving&quot;, xlab= &quot;Number of Crashes&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/LC5bX7Q/Histograms.jpg&quot; alt=&quot;image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Our sample size is low with only eleven and not normally distributed, so we will go ahead and use the Mann-Whitney U test&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Test&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The code for running this test is as simple as running a t-test in R. Just input the datasets inside the function “Wilcox.test”&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wilcox.test(Utah_crash$Alcohol,Utah_crash$Distracted)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Much like the t-test, this will provide a p-value to show if there is a statistically significant difference. In this case, the p-value was &lt;br /&gt;
&lt;img src=&quot;https://render.githubusercontent.com/render/math?math=2.8351422*10^{-6}&quot; /&gt;. If the alpha level was 0.05 (or even much lower than that),
this value would show that there is a statistically significant difference (as expected).&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;Using non-parametric tests will expand your statistical analysis skill set.
You can use them when parametric tests will not be as effective or just obsolete.
Sometimes it is best to use both and compare which test is more effective, then use the better one. As you can imagine,
non-parametric tests do not end with the two tests we talked about. Bootstraping and permuation tests are forms of
non-parametric tests that are also very effective under certain circumstances.
With this knowledge, we encourage you to use both parametric and non-parametric tests on a couple of datasets to see how
they compare and how effective non-parametric tests can be in certain circumstances.&lt;/p&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_nonparametric/bs704_nonparametric4.html &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/R/R4_One-TwoSampleTests-ANOVA/R4_One-TwoSampleTests-ANOVA5.html &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://publicsafety.utah.gov/ &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Jeong Heon You</name><email>nan</email></author><category term="R" /><category term="Non-Parametric tests" /><category term="Mann-Whitney U Test" /><category term="Utah Car Crashes" /><summary type="html">Non-Parametric Tests: Statistically Efficient or Technically Cheating?</summary></entry><entry><title type="html">Python in Visual Studio Code</title><link href="/blog/vscode" rel="alternate" type="text/html" title="Python in Visual Studio Code" /><published>2021-11-12T00:00:00-07:00</published><updated>2021-11-12T00:00:00-07:00</updated><id>/blog/vscode</id><content type="html" xml:base="/blog/vscode">&lt;h1 id=&quot;ide&quot;&gt;IDE&lt;/h1&gt;

&lt;p&gt;In today’s world, coding has become an essential part of us. Apple’s CEO, Tim Cook, elaborated in the recent Silicon Slope Summit, “Teaching someone to code teaches them critical thinking skills … coding teaches you the art of the possible … you need to learn how to code even if you’re not going to be a coder.” Everyone needs to learn how to code!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-12/img1.jpg&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As many would agree, the first step to start coding is to choose a language to code in. Once you decide a language to learn, you then get to choose an IDE, the Integrated Development Environment. Having an appropriate IDE can enhance your coding experience and help you become a better coder, in general. Examples of some of the famous IDEs are Xcode, Eclipse, Atom, Sublime Text, Komodo, PyCharm, and Microsoft Visual Studio. Each IDEs are usaully known for its effectiveness on a certain language. For example, Eclipse and Komodo is known for its use with Java, and PyCharm for Python. There are also IDEs that are used for general coding, with extensions to help with specific languages. These include Xcode, Atom, Sublime Text, and Microsoft Visual Studio. 
In case of Microsoft Visual Studio, Microsoft has divided its IDE into two, Visual Studio and Visual Studio Code, to maximize its individual usage. Visual Studio is a “full-featured” and “convenient” development environment mainly for C# and ASP .NET, while Visual Studio Code is a cross-platform (Windows, MacOS, Linux) editor that utilizes extensions/plugins to work with many languages. 
As someone who is very interested in Front-end Web app developing and user experience, I have been using Visual Studio Code for a while, and it is superb. Since Visual Studio Code utilizes plugins, it can also be used with Python and even with Jupyter Notebook files (.ipynb).&lt;/p&gt;

&lt;p&gt;This post will briefly illustrate how to set up Microsoft Visual Studio Code to work with Python.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-12/img2.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;visual-studio-code-vs&quot;&gt;Visual Studio Code vs.&lt;/h1&gt;
&lt;p&gt;“Why would you use Visual Studio Code instead of other IDEs like Jupyter Notebook or PyCharm?”
Well… I’m just familiar with Visual Studio Code (simply called as VS Code) with my use for web development. You could use any IDE of your choice, but VS Code’s UX is very user friendly. It can also do anything Jupyter Notebook can do, except the only bothersome would be that you would have to install more packages compared to Jupyter Notebook.&lt;/p&gt;

&lt;h1 id=&quot;overview&quot;&gt;Overview&lt;/h1&gt;

&lt;p&gt;Well, let’s first see an overview of what Visual Studio Code is capable of.&lt;/p&gt;

&lt;p&gt;Theme
I would joke with my co-workers saying, “You’re not a coder if it’s not on dark mode”. VS Code offers many pre-built themes that makes it look cool. This doesn’t change any functionality, but only the looks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-12/img3.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Terminal
Typing Ctrl + Shift + ` opens up integrated terminal that you can reference to while you work on your project.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-12/img4.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Explorer View
The explorer view is phenomenal. It provides a tree-view of the directories. You can easily add another file to the working directory and keep track of it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-12/img5.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;installation-and-set-up&quot;&gt;Installation and Set Up&lt;/h1&gt;
&lt;p&gt;If you are interested, you can go to &lt;a href=&quot;https://code.visualstudio.com/download&quot;&gt;Microsoft Visual Studio Code&lt;/a&gt; to install VS Code. Once you have Visual Studio installed, you can install extensions by opening the extension tab (Ctrl + Shift + X). You will be able to see a list of extensoins you have installed, which should be none. The packages you need are as the following:
(note: you wouldn’t need to download all of it, since it will automatically download dependencies, but I’ll leave it in case it doesn’t)
    1. Python
    2. Pylance
    3. Jupyter
    4. Jupyter Keymap
    5. Jupyter Notebook Renderers
Once you have all of these, then you’re all set! You may create or open a .ipynb file or .py file. In case of working with .py file, if you want to open a kernel, you can type #%% and run.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-12/img6.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note that you will have to install additional packages through the terminal. A safe way of saving packages and running python is through having a local environment, but for this blog’s purposes, we’ll just install to the public environment. Type in the following on the terminal (Ctrl + Shift + `).&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;numpy
pip3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;pandas

pip3 &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;sklearn
&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Sklearn requires additional installs. You may follow the prompt given once you run sklearn-related components.&lt;/p&gt;

&lt;p&gt;If you need to download anything, or update any existing packages, you can easily open terminal and do so.&lt;/p&gt;

&lt;h1 id=&quot;github&quot;&gt;GitHub&lt;/h1&gt;
&lt;p&gt;A good feature of VS Code is its effectiveness of source control through GitHub. It is good to practice and learn how to use git at the terminal, but once you get used to it, it gets a little bit bothersome to type in everything sometimes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-12/img7.png&quot; alt=&quot;screenshot&quot; /&gt;
&lt;img src=&quot;/assets/images/blogimages/figs-11-12/img8.png&quot; alt=&quot;screenshot&quot; /&gt;
&lt;img src=&quot;/assets/images/blogimages/figs-11-12/img9.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see, the left pane provides a source control option, where you can type in your commit message and pull/push when needed. Also, the bottom pane indicates whether the repository you are currently working on has updates. You can also easily set up branches and work as a team with VS Code.&lt;/p&gt;

&lt;p&gt;Sometimes, VS Code has many repositories and doesn’t save the last repositories you have worked on, not showing all of them. Then, you could go to the directory on your local machine in the terminal to re-instantiate the repository.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git init
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Everyone has different preferences. The main purpose of this blog wasn’t to persuade you to use VS Code, but to try an IDE that best fits you. In my case, VS Code works best. For some, having different IDEs for different languages may work better.&lt;/p&gt;

&lt;p&gt;If there are things I could improve on, please don’t hesitate to let me know! I’m all ears :)&lt;/p&gt;

&lt;p&gt;-JH
&lt;a href=&quot;https://www.linkedin.com/in/jacobjhunsaker/&quot;&gt;LinkedIn&lt;/a&gt; | &lt;a href=&quot;https://github.com/mimanjh&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;</content><author><name>Jacob Hunsaker</name><email>jacob.hunsaker96@gmail.com</email></author><category term="IDE" /><category term="python" /><category term="vs-code" /><summary type="html">IDE</summary></entry><entry><title type="html">Ace Your Data Science Interview</title><link href="/blog/Ace-The-Interview" rel="alternate" type="text/html" title="Ace Your Data Science Interview" /><published>2021-11-11T00:00:00-07:00</published><updated>2021-11-11T00:00:00-07:00</updated><id>/blog/Ace-The-Interview</id><content type="html" xml:base="/blog/Ace-The-Interview">&lt;p&gt;Going into a data science related job interview, you can be sure that they will ask you questions about machine learning. We are going to go over some of the most common questions asked related to machine learning during data science job interviews so &lt;strong&gt;you&lt;/strong&gt; can be ready to catch your dream job.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-11/you1.png&quot; alt=&quot;you&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Machine learning uses artificial intelligence and computer science on data and algorithms to imitate human learning. It automates processes like model building and classifying that originally could only be done with human reasoning. Through machine learning, we can teach algorithms with data to identify patterns and make decisions.&lt;/p&gt;

&lt;p&gt;Machine learning is growingly popular because instead of hard coding to solve problems, we can give the computers the data and let them learn from it. Companies are then able to identity risks or areas for profit or even implement machine learning into the product they are creating. The point is, any business can benefit from machine learning.&lt;/p&gt;

&lt;p&gt;We are going to look over 5 popular machine learning interview questions and talk about how to answer them.&lt;/p&gt;

&lt;h2 id=&quot;1-what-are-different-types-of-machine-learning-algorithms&quot;&gt;1.	What are different types of machine learning algorithms?&lt;/h2&gt;

&lt;p&gt;Supervised Learning- generally the model is trained with an input data set until it can correctly predict the output when given the same features it was trained on.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;An example of this would be housing prices. A data set might include features relating to when the house was built, how big it is, how many bedrooms it has, and the sale price. The classification method we choose would then identify the patterns of house features compared to their sale prices. In the end, we would hope to come out with a model that could be given data about a house and give you an accurate prediction of its sale price.&lt;br /&gt;
Unsupervised Learning- using unlabeled datasets, these methods will attempt to identify the structure of the data and group it based on its similarities.&lt;/li&gt;
  &lt;li&gt;An example of unsupervised learning would be inputting images of cities and rural landscapes and letting the machine identify features common to cityscapes and features common to rural landscapes, hopefully then allowing it to receive an image and categorize it correctly as city or rural.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-11/MLgraphic.jpeg&quot; alt=&quot;ML&quot; /&gt;
&lt;a href=&quot;https://medium.com/@dkatzman_3920/supervised-vs-unsupervised-learning-and-use-cases-for-each-8b9cc3ebd301&quot;&gt;Supervised vs. Unsupervised Learning&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-what-is-naïve-about-naïve-bayes&quot;&gt;2.	What is ‘Naïve’ about Naïve Bayes?&lt;/h2&gt;
&lt;p&gt;Naïve bayes is an algorithm used for predictive modeling that falls under the supervised learning category. The part that is naïve is that it assumes that every input variable is independent. Wikipedia gives a good example related to the following: A naïve bayes algorithm could be used to classify emails as spam or not spam. Features might count occurrences of certain words and then the email would be classified as spam or not spam. The algorithm would calculate the probability of it being spam based off the assumption that the occurrence of one word is independent from the occurrence of any other word.
This algorithm is commonly used with text classification problems or with multi-class prediction.&lt;/p&gt;

&lt;h2 id=&quot;3--how-much-data-should-you-allocate-for-your-training-validation-and-test-sets&quot;&gt;3.	 How much data should you allocate for your training, validation, and test sets?&lt;/h2&gt;
&lt;p&gt;A good rule of thumb is 80% in the train dataset and 20% in the test. However, each problem varies so there isn’t an answer that is always correct. You want to optimize for low variance on your model performance statistic and well as low variance on your actual model parameters.&lt;/p&gt;

&lt;h2 id=&quot;4-what-are-the-advantages-and-disadvantages-of-decision-trees&quot;&gt;4.	What are the advantages and disadvantages of decision trees?&lt;/h2&gt;
&lt;p&gt;Pros: Decision trees are easy to interpret, robust to outliers, and have fewer parameters to tune
Cons: More likely to be overfit, meaning a higher variance.&lt;/p&gt;

&lt;h2 id=&quot;5-how-can-we-handle-outlier-values&quot;&gt;5.	How can we handle outlier values?&lt;/h2&gt;
&lt;p&gt;Some tools used to discover outlier values include box plot, z-score, and scatterplots.
To handle any outliers we find, we can drop those observations from the dataset, impute a different value (ex. the mean), or you could segment them and analyze what insights you might gain from those data points.&lt;/p&gt;

&lt;h2 id=&quot;6-what-is-the-roc-curve-and-what-is-auc&quot;&gt;6.	What is the ROC Curve and what is AUC?&lt;/h2&gt;
&lt;p&gt;ROC stands for receiver operating characteristics. The ROC curve is a graph that shows the tradeoff between the true positive rate and the false positive rate. The ROC curve displays how good your model is at distinguishing between classes. The AUC is the area under the ROC curve and will always be between 0 and 1. Siladittya Manna on medium says it well -&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“AUC score is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-11/ROC.png&quot; alt=&quot;ROC&quot; /&gt;
&lt;a href=&quot;https://medium.com/@dkatzman_3920/supervised-vs-unsupervised-learning-and-use-cases-for-each-8b9cc3ebd301&quot;&gt;ROC Curve&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Just as a reminder, the true positive rate (TPR) is when a model correctly predicts a positive class. Think of a covid test: a 1.0 TPR means that every person with active Covid who took a Covid test would get a positive test result.
The False positive rate (FPR) measures how often the model incorrectly classifies a negative as a positive. This would be like a Covid test coming back positive when the person does not actually have covid.
The goal for any model is to correctly classify positives as positives and negatives as negatives, so a ROC curve with an AUC close to 1 is a good indicator that your model is performing well.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-11/cheer.png&quot; alt=&quot;cheer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These 5 questions don’t even begin to cover the scope of what interviewers might want to pry out of you during an interview, but it’s a good start to thinking about what you might want to freshen up on before heading into your next interview. Either way, be confident in what you do know and try to derive answers from that if a question trips you up. Preparation is key and practicing explaining these concepts to another person is one of the best ways to see how well you really know what you think you know. Thanks for reading and best of luck!&lt;/p&gt;

&lt;h3 id=&quot;sources&quot;&gt;Sources&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;Below are the sources used for the interview questions and information used in the answers.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pages.github.com/&quot;&gt;IBM Machine Learning&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pages.github.com/&quot;&gt;Machine Learning Q&amp;amp;A (Elite Data Science)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pages.github.com/&quot;&gt;Machine Learning Q&amp;amp;A (Interview Bit)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pages.github.com/&quot;&gt;Machine Learning Algorithms&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pages.github.com/&quot;&gt;Naive Bayes&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Image Links:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://unsplash.com/&quot;&gt;Stock Photos&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/@dkatzman_3920/supervised-vs-unsupervised-learning-and-use-cases-for-each-8b9cc3ebd301&quot;&gt;ROC Curve&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/@dkatzman_3920/supervised-vs-unsupervised-learning-and-use-cases-for-each-8b9cc3ebd301&quot;&gt;Supervised vs. Unsupervised Learning&lt;/a&gt;&lt;/p&gt;</content><author><name>Ashtyn Fiala</name><email>fialaae@gmailcom</email></author><category term="machine learning" /><category term="job search" /><category term="algorithms" /><category term="interview questions" /><summary type="html">Going into a data science related job interview, you can be sure that they will ask you questions about machine learning. We are going to go over some of the most common questions asked related to machine learning during data science job interviews so you can be ready to catch your dream job.</summary></entry><entry><title type="html">Writing Code in RStudio - Helpful Tips and Tricks</title><link href="/blog/RStudio-tips" rel="alternate" type="text/html" title="Writing Code in RStudio - Helpful Tips and Tricks" /><published>2021-11-10T00:00:00-07:00</published><updated>2021-11-10T00:00:00-07:00</updated><id>/blog/RStudio-tips</id><content type="html" xml:base="/blog/RStudio-tips">&lt;p&gt;RStudio is a widely used platform for coding. It has a host of shortcuts and cool features that streamline the coding process. Here are 10 that have been a huge benefit to me.&lt;/p&gt;

&lt;h2 id=&quot;access-all-shortcuts&quot;&gt;Access All Shortcuts&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Alt + Shift + K&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you ever want a reminder on a particular shortcut, you can pull up a list of all shortcuts available in RStudio by pressing &lt;strong&gt;Alt + Shift + K&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;navigating-open-files&quot;&gt;Navigating Open files&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Ctrl + Tab&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Ctrl + Shift + Tab&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Ctrl + Shift + .&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you are like me, you probably have multiple files open at once in RStudio. Instead of having to drag your mouse and click on a file you want to pull up, you can instead skim over tabs by pressing &lt;strong&gt;Ctrl + Tab&lt;/strong&gt; (to go one tab to the right) or &lt;strong&gt;Ctrl + Shift + Tab&lt;/strong&gt; (to go one tab to the left). If you have a ton of tabs open, it may be simpler to press &lt;strong&gt;Ctrl + Shift + .&lt;/strong&gt; which allows you to search by name all of the files you have open.&lt;/p&gt;

&lt;h2 id=&quot;multiple-cursors--selections&quot;&gt;Multiple Cursors / Selections&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Alt + Ctrl + Click&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Ctrl + Alt + Shift + M&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Have you ever felt yourself wanting to edit similar parts of your code at once? RStudio has a few features that make this easy. The multiple cursor feature is one of my favorites. If you hold &lt;strong&gt;Alt + Ctrl&lt;/strong&gt;, you can click and put multiple cursors in your code, which is very helpful if you need to cut/copy and paste multiple sections of code, or if you need to make small adjustments in several places. Holding &lt;strong&gt;Alt + Ctrl + Up/Down&lt;/strong&gt; will add additional cursors directly above or below where the current cursor is.&lt;/p&gt;

&lt;p&gt;If you want to select all instances of a particular phrase or section of code within a script, select one instance, then hold &lt;strong&gt;Ctrl + Alt + Shift + M.&lt;/strong&gt; All instances of that selection within the script will be selected, making it easy to make quick adjustments.&lt;/p&gt;

&lt;h2 id=&quot;pipe-operators&quot;&gt;Pipe Operators&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;%&amp;gt;%&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;%&amp;lt;&amp;gt;%&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;%$%&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As with many other languages, R has a piping function (available from the magrittr package) which allows for more streamlined and easy-to-follow code. For example, the code:&lt;/p&gt;

&lt;div class=&quot;language-md highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x &amp;lt;- data.frame(“V1” = c(1, 2, 3), “V2” = c(“a”, “b”, “c”))
mean(pull(filter(x,V1 %in% c(&quot;a&quot;,&quot;b&quot;)),V2))
&lt;span class=&quot;gh&quot;&gt;# 1.5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Can be rewritten as the following using the pipe function:&lt;/p&gt;

&lt;div class=&quot;language-md highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x %&amp;gt;% filter(V1 %in% c(&quot;a&quot;,&quot;b&quot;)) %&amp;gt;% pull(V2) %&amp;gt;% mean()
&lt;span class=&quot;gh&quot;&gt;# 1.5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In RStudio, instead of having to manually type out the function, press &lt;strong&gt;Ctrl + Shift + M&lt;/strong&gt; for an efficient way to insert the function.&lt;/p&gt;

&lt;p&gt;There are a couple of other pipe operators as part of the magrittr package that I think are interesting. The operator %&amp;lt;&amp;gt;% allows you to simultaneously pipe an object and save the updates to that object. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;x &amp;lt;- data.frame(“V1” = c(1, 2, 3), “V2” = c(“a”, “b”, “c”))
x &amp;lt;- x %&amp;gt;% select(V1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;can be rewritten as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;x %&amp;lt;&amp;gt;% select(V1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The operator %$% allows you to pull a specific column from a data frame, which can be useful, especially when used as part of a sequence of piped functions. For example, the code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;x %$% V1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;will extract the vector c(1, 2, 3) from the data frame.&lt;/p&gt;

&lt;h2 id=&quot;quick-code-manipulations&quot;&gt;Quick Code Manipulations&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Alt + Up/Down&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Alt + Shift + Up/Down&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These next tricks are helpful for editing lines of code in your document. Holding &lt;strong&gt;Alt + Up/Down&lt;/strong&gt; allows you to move whichever line(s) your cursor is on Up or Down, respectively. It allows you to move code pretty effectively around your document.&lt;/p&gt;

&lt;p&gt;If you would like to make a quick copy of a line of code, just add shift to the mix (&lt;strong&gt;Alt + Shift + Up/Down&lt;/strong&gt;) to copy the selected line(s) in the direction you specify.&lt;/p&gt;

&lt;h2 id=&quot;snippets&quot;&gt;Snippets&lt;/h2&gt;
&lt;p&gt;A really cool feature of RStudio is the ability to define custom shortcuts to generate code, called snippets. RStudio has several snippets predefined and ready to use. For example, if you type “mat” and press &lt;strong&gt;Tab&lt;/strong&gt;, RStudio returns a template for the matrix function, and allows the user to quickly tab over to specify the contents of the matrix and specify the number of rows and columns. To see what snippets are available in RStudio, as well as to define your own snippets, go to Tools &amp;gt; Global Options &amp;gt; Code &amp;gt; Edit Snippets… I have saved several presets for repetitive tasks that I do often, such as generating a header for scripts and setting the working directory to the file’s location. This has saved me a ton of time. For more information on snippets visit &lt;a href=&quot;https://support.rstudio.com/hc/en-us/articles/204463668-Code-Snippets?version=1.4.1717&amp;amp;mode=desktop&quot;&gt;this website&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;jumping-from-script-to-console&quot;&gt;Jumping from script to console&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Ctrl + 1&lt;/em&gt; / &lt;em&gt;Ctrl + Shift + 1&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Ctrl + 2&lt;/em&gt; / &lt;em&gt;Ctrl + Shift + 2&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are several shortcuts that allow you to jump around to the different panes in RStudio. The keys &lt;strong&gt;1-9&lt;/strong&gt; and &lt;strong&gt;F1-F7&lt;/strong&gt; are each associated with a particular pane in RStudio (a complete list of associations can be found by holding &lt;strong&gt;Alt + Shift + K&lt;/strong&gt;). Holding &lt;strong&gt;Ctrl + {Pane #}&lt;/strong&gt; will bring the particular pane to the foreground along with the cursor. Holding &lt;strong&gt;Ctrl + Shift + {Pane #}&lt;/strong&gt; will maximize that pane so that it fills the window. I most often use these shortcuts to jump from the source pane to the console pane and back (&lt;strong&gt;Ctrl + 1/2&lt;/strong&gt;) or to maximize one of these panes (&lt;strong&gt;Ctrl + Shift + 1/2&lt;/strong&gt;).&lt;/p&gt;

&lt;h2 id=&quot;comments&quot;&gt;Comments&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Ctrl + Shift + C&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Colored Comments&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You probably know that adding a pound sign at the beginning of a line of code will comment it out. It can be a pain to manually add the sign to several lines that we want to comment out. Instead, we can select the lines of code that we want to comment out and press &lt;strong&gt;Ctrl + Shift + C&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Sometimes it can be helpful to have different colored comments in your code (for example, having a particular color for notes, alternate code, etc…). While RStudio does not directly support this capability, we can hack it by using the following additions to the pound sign:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;#'[comment_here_in_color_1]
#'*comment_here_in_color_2*
#'@comment_here_in_color_3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The colors will differ based off of your selected theme&lt;/p&gt;

&lt;h2 id=&quot;theme&quot;&gt;Theme&lt;/h2&gt;

&lt;p&gt;The default RStudio theme is very light. Users can select a different color scheme by going to Tools &amp;gt; Global Options &amp;gt; and appearance. If your aren’t satisfied with any of them, you can create your own custom theme, and load it into RStudio (see this &lt;a href=&quot;https://rstudio.github.io/rstudio-extensions/rstudio-theme-creation.html&quot;&gt;webpage&lt;/a&gt; for more details).&lt;/p&gt;

&lt;h2 id=&quot;setting-working-directory&quot;&gt;Setting Working Directory&lt;/h2&gt;

&lt;p&gt;Sometimes it can be a pain to set the working directory, especially if you have to type out the entire file path. There is a nice function as part of the rstudioapi package that will set the working directory to the current file location:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;setwd(dirname(rstudioapi::getActiveWorkingContext()$path))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I have created my own snippet that will generate this line with a couple keystrokes. It saves a lot of time.&lt;/p&gt;

&lt;p&gt;It is important to note that this code only works in RStudio, and for an RScript. If you are working within an R Markdown document, it is a little harder to set the working directory, but the following code will work:&lt;/p&gt;

&lt;div class=&quot;language-md highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;{r}
&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;knitr::opts_knit$set(root.dir = 'your/file/path')&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Again, snippets work great here in allowing you to type the code quickly and effectively.&lt;/p&gt;

&lt;h2 id=&quot;r-markdown&quot;&gt;R Markdown&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;message&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;warning&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;cache&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Many who read this article will undoubtedly be familiar with R Markdown files, which provides a nice way to format code and text for reports or presentations. I have been using R Markdowns for a few years now, and I keep discovering new features that I wish I had known from the beginning. Here are a few pointers that will make your experience more enjoyable. (As a quick comment, the knitr package must be installed in order to knit an R Markdown file)&lt;/p&gt;

&lt;p&gt;To quickly insert a new code chunk, press &lt;strong&gt;Ctrl + Alt + i&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;At the beginning of each code chunk there is a heading contained in curly braces:&lt;/p&gt;
&lt;div class=&quot;language-md highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;{r chunk_name, additional_options...}
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Text immediately following the “r” is the chunk’s name, which, beyond idenitfying the portion of code, can be used to access the chunk quickly in the source pane in RStudio. Additional options that control specific display features of the chunk can be set following the name.&lt;/p&gt;

&lt;p&gt;If you want to have all the same options specified for all chunks in the document, include the following line of code in the document:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;knitr::opts_chunk$set(options_for_all_chunks)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The space within the parantheses is where the user can specify the options that apply to every chunk in the document.&lt;/p&gt;

&lt;p&gt;I often have been frustrated by the appearance of unwanted messages or warnings that were generated by the code in the R Markdown. Specifying the options &lt;strong&gt;message=FALSE&lt;/strong&gt; and &lt;strong&gt;warning=FALSE&lt;/strong&gt; in the heading will remove this output from the knitted document.&lt;/p&gt;

&lt;p&gt;Another frustration was that knitting required all the code in the document to compile before generating a report. This was especially frustrating as I neared the end of projects and needed to see how the document looked as I was making final adjustment changes. Adding the option &lt;strong&gt;cache=TRUE&lt;/strong&gt; makes it so that any chunk that has already been compiled and has no adjustments does not have to be recompiled in order to generate a report. This option has saved me a lot of time and frustration.&lt;/p&gt;

&lt;p&gt;To see more available options for R Markdown code chunks, along with other useful features, check out &lt;a href=&quot;https://ethz.ch/content/dam/ethz/special-interest/math/statistics/sfs/Education/Advanced%20Studies%20in%20Applied%20Statistics/course-material-1921/Datenanalyse/rmarkdown-2.pdf&quot;&gt;this pdf&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This is by no means a comprehensive list of all the helpful features in RStudio, but these are several that I have found useful in my educational and career experience. I hope that they can be helpful to you as well. If you have any tips or tricks that you find useful, please comment them below!&lt;/p&gt;

&lt;p&gt;Happy coding!&lt;/p&gt;</content><author><name>McKay Gerratt</name><email>mckayger@gmail.com</email></author><category term="R" /><category term="Interface" /><category term="RStudio" /><category term="Shortcuts" /><category term="Custom" /><category term="Efficient Coding" /><summary type="html">RStudio is a widely used platform for coding. It has a host of shortcuts and cool features that streamline the coding process. Here are 10 that have been a huge benefit to me. Access All Shortcuts Alt + Shift + K If you ever want a reminder on a particular shortcut, you can pull up a list of all shortcuts available in RStudio by pressing Alt + Shift + K. Navigating Open files Ctrl + Tab Ctrl + Shift + Tab Ctrl + Shift + . If you are like me, you probably have multiple files open at once in RStudio. Instead of having to drag your mouse and click on a file you want to pull up, you can instead skim over tabs by pressing Ctrl + Tab (to go one tab to the right) or Ctrl + Shift + Tab (to go one tab to the left). If you have a ton of tabs open, it may be simpler to press Ctrl + Shift + . which allows you to search by name all of the files you have open. Multiple Cursors / Selections Alt + Ctrl + Click Ctrl + Alt + Shift + M Have you ever felt yourself wanting to edit similar parts of your code at once? RStudio has a few features that make this easy. The multiple cursor feature is one of my favorites. If you hold Alt + Ctrl, you can click and put multiple cursors in your code, which is very helpful if you need to cut/copy and paste multiple sections of code, or if you need to make small adjustments in several places. Holding Alt + Ctrl + Up/Down will add additional cursors directly above or below where the current cursor is. If you want to select all instances of a particular phrase or section of code within a script, select one instance, then hold Ctrl + Alt + Shift + M. All instances of that selection within the script will be selected, making it easy to make quick adjustments. Pipe Operators %&amp;gt;% %&amp;lt;&amp;gt;% %$% As with many other languages, R has a piping function (available from the magrittr package) which allows for more streamlined and easy-to-follow code. For example, the code: x &amp;lt;- data.frame(“V1” = c(1, 2, 3), “V2” = c(“a”, “b”, “c”)) mean(pull(filter(x,V1 %in% c(&quot;a&quot;,&quot;b&quot;)),V2)) # 1.5 Can be rewritten as the following using the pipe function: x %&amp;gt;% filter(V1 %in% c(&quot;a&quot;,&quot;b&quot;)) %&amp;gt;% pull(V2) %&amp;gt;% mean() # 1.5 In RStudio, instead of having to manually type out the function, press Ctrl + Shift + M for an efficient way to insert the function. There are a couple of other pipe operators as part of the magrittr package that I think are interesting. The operator %&amp;lt;&amp;gt;% allows you to simultaneously pipe an object and save the updates to that object. For example: x &amp;lt;- data.frame(“V1” = c(1, 2, 3), “V2” = c(“a”, “b”, “c”)) x &amp;lt;- x %&amp;gt;% select(V1) can be rewritten as x %&amp;lt;&amp;gt;% select(V1) The operator %$% allows you to pull a specific column from a data frame, which can be useful, especially when used as part of a sequence of piped functions. For example, the code: x %$% V1 will extract the vector c(1, 2, 3) from the data frame. Quick Code Manipulations Alt + Up/Down Alt + Shift + Up/Down These next tricks are helpful for editing lines of code in your document. Holding Alt + Up/Down allows you to move whichever line(s) your cursor is on Up or Down, respectively. It allows you to move code pretty effectively around your document. If you would like to make a quick copy of a line of code, just add shift to the mix (Alt + Shift + Up/Down) to copy the selected line(s) in the direction you specify. Snippets A really cool feature of RStudio is the ability to define custom shortcuts to generate code, called snippets. RStudio has several snippets predefined and ready to use. For example, if you type “mat” and press Tab, RStudio returns a template for the matrix function, and allows the user to quickly tab over to specify the contents of the matrix and specify the number of rows and columns. To see what snippets are available in RStudio, as well as to define your own snippets, go to Tools &amp;gt; Global Options &amp;gt; Code &amp;gt; Edit Snippets… I have saved several presets for repetitive tasks that I do often, such as generating a header for scripts and setting the working directory to the file’s location. This has saved me a ton of time. For more information on snippets visit this website. Jumping from script to console Ctrl + 1 / Ctrl + Shift + 1 Ctrl + 2 / Ctrl + Shift + 2 There are several shortcuts that allow you to jump around to the different panes in RStudio. The keys 1-9 and F1-F7 are each associated with a particular pane in RStudio (a complete list of associations can be found by holding Alt + Shift + K). Holding Ctrl + {Pane #} will bring the particular pane to the foreground along with the cursor. Holding Ctrl + Shift + {Pane #} will maximize that pane so that it fills the window. I most often use these shortcuts to jump from the source pane to the console pane and back (Ctrl + 1/2) or to maximize one of these panes (Ctrl + Shift + 1/2). Comments Ctrl + Shift + C Colored Comments You probably know that adding a pound sign at the beginning of a line of code will comment it out. It can be a pain to manually add the sign to several lines that we want to comment out. Instead, we can select the lines of code that we want to comment out and press Ctrl + Shift + C. Sometimes it can be helpful to have different colored comments in your code (for example, having a particular color for notes, alternate code, etc…). While RStudio does not directly support this capability, we can hack it by using the following additions to the pound sign: #'[comment_here_in_color_1] #'*comment_here_in_color_2* #'@comment_here_in_color_3 The colors will differ based off of your selected theme Theme The default RStudio theme is very light. Users can select a different color scheme by going to Tools &amp;gt; Global Options &amp;gt; and appearance. If your aren’t satisfied with any of them, you can create your own custom theme, and load it into RStudio (see this webpage for more details). Setting Working Directory Sometimes it can be a pain to set the working directory, especially if you have to type out the entire file path. There is a nice function as part of the rstudioapi package that will set the working directory to the current file location: setwd(dirname(rstudioapi::getActiveWorkingContext()$path)) I have created my own snippet that will generate this line with a couple keystrokes. It saves a lot of time. It is important to note that this code only works in RStudio, and for an RScript. If you are working within an R Markdown document, it is a little harder to set the working directory, but the following code will work: ```{r} knitr::opts_knit$set(root.dir = 'your/file/path') ``` Again, snippets work great here in allowing you to type the code quickly and effectively. R Markdown message warning cache Many who read this article will undoubtedly be familiar with R Markdown files, which provides a nice way to format code and text for reports or presentations. I have been using R Markdowns for a few years now, and I keep discovering new features that I wish I had known from the beginning. Here are a few pointers that will make your experience more enjoyable. (As a quick comment, the knitr package must be installed in order to knit an R Markdown file) To quickly insert a new code chunk, press Ctrl + Alt + i. At the beginning of each code chunk there is a heading contained in curly braces: ```{r chunk_name, additional_options...} ``` Text immediately following the “r” is the chunk’s name, which, beyond idenitfying the portion of code, can be used to access the chunk quickly in the source pane in RStudio. Additional options that control specific display features of the chunk can be set following the name. If you want to have all the same options specified for all chunks in the document, include the following line of code in the document: knitr::opts_chunk$set(options_for_all_chunks) The space within the parantheses is where the user can specify the options that apply to every chunk in the document. I often have been frustrated by the appearance of unwanted messages or warnings that were generated by the code in the R Markdown. Specifying the options message=FALSE and warning=FALSE in the heading will remove this output from the knitted document. Another frustration was that knitting required all the code in the document to compile before generating a report. This was especially frustrating as I neared the end of projects and needed to see how the document looked as I was making final adjustment changes. Adding the option cache=TRUE makes it so that any chunk that has already been compiled and has no adjustments does not have to be recompiled in order to generate a report. This option has saved me a lot of time and frustration. To see more available options for R Markdown code chunks, along with other useful features, check out this pdf. Conclusion This is by no means a comprehensive list of all the helpful features in RStudio, but these are several that I have found useful in my educational and career experience. I hope that they can be helpful to you as well. If you have any tips or tricks that you find useful, please comment them below! Happy coding!</summary></entry><entry><title type="html">The heart of Deep Learning</title><link href="/blog/neural-networks" rel="alternate" type="text/html" title="The heart of Deep Learning" /><published>2021-11-09T00:00:00-07:00</published><updated>2021-11-09T00:00:00-07:00</updated><id>/blog/neural-networks</id><content type="html" xml:base="/blog/neural-networks">&lt;h3 id=&quot;introduction---what-is-a-neural-network&quot;&gt;Introduction - What is a neural network?&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-09/neural%20network.PNG&quot; alt=&quot;nn&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Neural networks are a form of machine learning composed of layers of nodes whose role is to learn patterns in the training data fed to it and match those patterns 
to the label set for each item. The example we will run through is a data set which contains images of numbers 0 through 9 with their respective labels. Our goal
is to effectively determine which number corresponds to each image.&lt;/p&gt;

&lt;p&gt;In simple words, a neural network has an input layer (we input each image), an output layer (the layer that outputs which number the image represents), and several
hidden layers in between through which each image runs. Weights are assigned to each node that represent the importance of that particular characteristic in the data
in order to eventually determine the final prediction. The following is an example of how we might think of this process.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-09/example%20nodes.PNG&quot; alt=&quot;example&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When we determine whether the image above is a six, we might perhaps look for certain characteristics. For example, we might be looking for a circle or an oval connected to
a diagonal or curved line above it. A neural network works similarly in the sense that it looks for patterns that will help it determine whether it is looking at a six or
another number. Each layer and node will look at a different piece and, in the end, it will put all those pieces together. Now, let’s dive a little deeper.&lt;/p&gt;

&lt;h3 id=&quot;install-keras&quot;&gt;Install Keras&lt;/h3&gt;

&lt;p&gt;On your terminal window, run the following command:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip install keras&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;dependencies-for-this-example&quot;&gt;Dependencies for this example&lt;/h3&gt;

&lt;p&gt;For our example, you will need to install the following libraries&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np
from random import randint
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import itertools
import os.path as path

import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We will not go through the cleanup and prepping of the data in this article but you can find the complete jupyter notebook with more detail &lt;a href=&quot;https://github.com/jpablohigueros/KerasIntro&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;creating-a-neural-network&quot;&gt;Creating a neural network&lt;/h3&gt;

&lt;p&gt;Keras is equipped with different ways to build your model. However, the Sequential model is the simplest and for our basic example, it will suffice. We instantiate our
model object with the command &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model = Sequential()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Next, we have to create layers. Some of the most common types of layers are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Dense (Fully interconnected)&lt;/li&gt;
  &lt;li&gt;Convolucionary (Image data)&lt;/li&gt;
  &lt;li&gt;Recurrent (For time series)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In our prep work of the data, we have vectorized and normalized each image into an array of values between 0 and 1. Therefore, we will use Dense layers to analyze the data.
We add a layer to our model like so:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Define input layer
layer_input = Dense(units=512, activation='sigmoid', input_shape=(image_size,))
# Add layer to model
model.add(layer_input)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The units are the number of neurons within the layer and choosing the number is outside the scope of this article. The activation function determines the output from the node
based on the input. In this case we use the Sigmoid function because it takes in input between 0 and 1. The correct activation function depends much on the type of input of output in your data.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-09/activation%20functions.png&quot; alt=&quot;activation&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Identity (linear)&lt;/li&gt;
  &lt;li&gt;Binary (Non-negative input outputs 1 and negative input outputs 0)&lt;/li&gt;
  &lt;li&gt;Sigmoid (Logistic; contains input from 0 to 1)&lt;/li&gt;
  &lt;li&gt;TanH (Similar to sigmoid but from -1 to 1)&lt;/li&gt;
  &lt;li&gt;ArcTan (Contains from -pi/2 to pi/2)&lt;/li&gt;
  &lt;li&gt;ReLu (Negative input returns 0 and positive input is linear)&lt;/li&gt;
  &lt;li&gt;Leaky ReLu (Negative input’s magnitude is reduced, positive input is linear)&lt;/li&gt;
  &lt;li&gt;Softmax (To impart probabilities, returns probability distribution)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We now add an additional layer and finally our output layer.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Define another layer
new_layer = Dense(units=512, activation='sigmoid')
model.add(new_layer)

layer_output = Dense(units=10, activation='softmax', input_shape=(image_size,))
model.add(layer_output)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For the output layer, we choose 10 units because we are trying to determine which number (from 0 to 9) corresponds to each image. We can see a summary of what our model looks
like before we compile it by running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model.summary()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-09/modelsummary.PNG&quot; alt=&quot;summary&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Before we compile it is important to understand two concepts that come into play in the compilation process: Loss functions and Optimizers.&lt;/p&gt;

&lt;h4 id=&quot;loss-functions&quot;&gt;Loss functions&lt;/h4&gt;

&lt;p&gt;Loss functions are functions that predict error in the within the neural network. The output of this function is called gradient and it is use to adjust the weights of each node.
The following are different loss functions available within Keras but we will not go into the specifics of each function:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;mean_squared_error&lt;/li&gt;
  &lt;li&gt;mean_absolute_error&lt;/li&gt;
  &lt;li&gt;mean_absolute_percentage_error&lt;/li&gt;
  &lt;li&gt;mean_squared_logarithmic_error&lt;/li&gt;
  &lt;li&gt;squared_hinge&lt;/li&gt;
  &lt;li&gt;hinge&lt;/li&gt;
  &lt;li&gt;categorical_hinge&lt;/li&gt;
  &lt;li&gt;logcosh&lt;/li&gt;
  &lt;li&gt;categorical_crossentropy&lt;/li&gt;
  &lt;li&gt;sparse_categorical_crossentropy&lt;/li&gt;
  &lt;li&gt;binary_crossentropy&lt;/li&gt;
  &lt;li&gt;kullback_leibler_divergence&lt;/li&gt;
  &lt;li&gt;poisson&lt;/li&gt;
  &lt;li&gt;cosine_proximity&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;optimizers&quot;&gt;Optimizers&lt;/h4&gt;

&lt;p&gt;Simply put, optimizers adjust features of the neural network to minimize losses. They use the gradients outputted by our loss functions. Some optimizers are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Gradient Descent&lt;/li&gt;
  &lt;li&gt;Stochastic Gradient Descent&lt;/li&gt;
  &lt;li&gt;Mini-Batch Gradient Descent&lt;/li&gt;
  &lt;li&gt;Adam&lt;/li&gt;
  &lt;li&gt;Momentum&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now that we understand these concepts, we can go ahead and compile the model with:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;model.compile(loss='sparse_categorical_crossentropy',
             optimizer='sgd',
             metrics=['accuracy'])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The metrics argument lets us chose what we will see in the output as we fit our model. In this case, we want to know how accurate our model is. We fit our model by running:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Fit the model to data and labels - also validate
model.fit(x_train, 
          y_train, 
          batch_size=10, 
          epochs=20, 
          shuffle=True, 
          verbose=True, 
          validation_split=.01)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-09/metrics.png&quot; alt=&quot;metrics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can learn more about what each argument means &lt;a href=&quot;https://keras.io/api/models/model_training_apis/&quot;&gt;here&lt;/a&gt;. However, an important argument to understand is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;validation_split&lt;/code&gt;. This argument is the portion of your training data that will be used to validate your model (not the same as testing) at the end of each time the data
goes through the model.&lt;/p&gt;

&lt;h3 id=&quot;testing-our-model&quot;&gt;Testing our model&lt;/h3&gt;

&lt;p&gt;We can make predictions with:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Make prediction on test data
predictions = model.predict(x=x_test, batch_size=10, verbose=0)

# round to nearest int to get the most likely prediction
rounded_preds = np.argmax(predictions, axis=-1)
y_true = np.argmax(y_test, axis=-1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We can create a confusion matrix to visualize the accuracy of our model’s predictions. This matrix contains the predicted value on the x axis and the true value on the y axis.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-11-09/confusion.png&quot; alt=&quot;matrix&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, Keras gives us the option to reuse an already trained model by saving it with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model.save('/model.ext')&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;This is a very simple and basic example of how a neural network works. However, can you see some of the potential uses of neural netwokrs? Neural networks are the basis of
facial recognition, hand-writting recognition among many others. It is the most basic way of deep learning and artificial intelligence. Because of this, it is important to
learn and understand how they work.&lt;/p&gt;</content><author><name>Pablo Higueros</name><email>nan</email></author><category term="Keras" /><category term="Neural Network" /><category term="Deep Learning" /><category term="Layers" /><category term="Sequential" /><summary type="html">Introduction - What is a neural network?</summary></entry></feed>