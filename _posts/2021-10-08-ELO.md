---
title: For When You've Gotten Serious about Board Games
layout: post
author: alenning
post-image: /assets/images/blogimages/figs-10-08/catan_board.jpg
description: A project for keeping track of a more accurate rating system, and then presenting ratings on a website.
tags:
- Pandas
- AWS
- API
- Google Sheets
- Group by
---

## Introduction

It's a Sunday Evening, and you're sitting around your dining room table with all of your family. Your dad has just won another board game and he's rubbing it in your face like he normally does. Some silly banter goes on amongst your siblings and eventually you all start fighting about who is the best in your family. Obviously your dad joins in and he has to add that he just won tonight's game **again** and he brags that he always wins. Well lucky for you that you just read a blog post detailing how one board game fanatic just implemented a rating system that even international chess federations use to compare player skill levels. And guess who has the guts to follow through and implement a similar one herself? That's right! You do! So get reading and see how you can turn the tables on your family and show them empirically who is the most skilled board game player.

_Warning: Implementing the following rating system may be toxic. Side effects may include: strained relationships with sore losers, lack of self-esteem, youtube rabbit-holes dedicated to learning the minute strategies of your board game, and much much more._

---

## Getting Started

Back at the beginning of the summer a conversation like the one detailed above took place amongst my group of friends. Having had a bit of experience with APIs and Pandas Dataframes, I thought I could create something simple enough yet valuable enough to see who was really the most skilled and how our skill grew over time. We were playing [Settlers of Catan](https://www.catan.com/), a popular board game where usually 4 players take turns placing settlements and growing their empire on the island of Catan. First person to reach 10 Victory Points (VPs) wins. Simple enough and yet the strategy is endless. 

At first I was mostly just interested in trying to predict who was going to win a game, and so I kept various statistics on games we played and the outcomes. Eventually I thought to put it into a google sheet to keep track of them in a cleaner way. Over time, my friends abused the google sheet saying that my win percentage was the highest and using that to collaborate against me in the game. At this point I thought to myself, there has to be a better way of knowing who is the best player. After doing some research online, a popular online version of the game was using something called an [ELO rating system](https://en.wikipedia.org/wiki/Elo_rating_system). To put it simply, the algorithm takes two players ratings, and figures our who is expected to win, and then makes calculations based on what the actual outcome is, similar to a residual. The larger the difference, the more extreme the rating change. The model is fun enough to spend a whole blog post for another class discussing, but ultimately I decided to try implementing it amongst my friends. What ensued was many hours of reading documentation and following tutorials on my own. This guide is designed to help you implement something simple, quick and impressive so that you can show off to family members, classmates, and even recruiters. All in all the project took me about 15 hours of work, but I've condensed a lot of the work I had to do, so if you follow this tutorial you should be able to get something up in about 3 hours, which is relatively quick for how impressive this is. The final project can be found here, at [adamlenning.com](http://adamlenning.com) (so that I can brag to all of you).

The basic outline for how this project is structured is split into 3 parts:

1. Reading data from Google Sheets
2. Performing calculations in Pandas
3. Uploading the results to an AWS-hosted website

---

## Reading Data from Google Sheets

The Google sheet I used for this project can be found [here](https://docs.google.com/spreadsheets/d/1MG7jhiarGpRunEILVbkEfD3mLRUBpIMI4au7cMID_EM/edit?usp=sharing). The exact format isn't relevant. The headings, and actual data can be whatever you would like, but what you do need is the name of the sheet located at the bottom of the page as well as the ID of the page found in the url.

![screenshot](/assets/images/blogimages/figs-10-08/sheet_info.png)

I followed the [python quickstart guide](https://developers.google.com/sheets/api/quickstart/python), and you'll need to do the same for the prerequisites. The prerequisites are extremely important and you won't be able to get data without properly completing those steps. The prerequisites give you the credentials you need to use the Google Sheets API and make the appropriate calls.

After you complete the prerequisites follow step 1. If you want a full list of the packages used in this project see the _requirements.txt_ file in the github repository for this project found at the end of the tutorial.

Now create a python file and lets get to work with some introductory lines of code, which will frame what we need for to make the api call. Make sure to substitute your range name with the name of your sheet, as well as the ID.

```python
from __future__ import print_function
import os.path
from googleapiclient.discovery import build
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials

# If modifying these scopes, delete the file token.json.
SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']

# The ID and range of a sample spreadsheet.
SAMPLE_SPREADSHEET_ID = '1MG7jhiarGpRunEILVbkEfD3mLRUBpIMI4au7cMID_EM'
SAMPLE_RANGE_NAME = 'Games'
```

I had stored everything in a class to make some of the work easier, but honestly if you are doing a small project then it won't matter too much. You can use what is inside this next function to pull what you need from your google sheet. The first couple if-statments are for authentication when you try running the script. If you have done the prerequisites correctly then when you run your program you it will open a browser tab asking you to allow access to google sheets. It may say that it is from an untrusted source, but unless you don't trust yourself then you can proceed.

This function creates the service variable which is basically your connection to your google sheet. Then you are going to call a get function and execute it which performs the API call and fetches your data in raw json format. We then get the values from the json data and then read them into a Pandas DataFrame. Now you're all ready for the next step.

```python
def get_games(self):
    creds = None
    # The file token.json stores the user's access and refresh tokens, and is
    # created automatically when the authorization flow completes for the first
    # time.
    if os.path.exists('token.json'):
        creds = Credentials.from_authorized_user_file('token.json', self.SCOPES)
    # If there are no (valid) credentials available, let the user log in.
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                'credentials.json', self.SCOPES)
            creds = flow.run_local_server(port=0)
        # Save the credentials for the next run
        with open('token.json', 'w') as token:
            token.write(creds.to_json())
            
    service = build('sheets', 'v4', credentials=creds)

    sheet = service.spreadsheets()
    result = sheet.values().get(spreadsheetId=self.SAMPLE_SPREADSHEET_ID,
                                range=self.SAMPLE_RANGE_NAME).execute()
    values = result.get('values', [])
    
    df = pd.DataFrame(values[1:], columns=values[0])
```

---

## Performing calculations in Pandas

There won't be much code cited in this part since you should be familiar with Pandas enough to do what you want with this data. As I mentioned earlier I implemented an ELO system and gave players ELO scores that reflects more accurately their relative skill to the player pool that we have. Generally groupby is going to be your friend in this section. Your individual stats that you are measuring are going to be the best indicator of what you want to present. Since I was gathering Victory Points for my Catan games, I grouped by player and then found the mean and standard deviation of everyones Victory Points.

When you're all done wrangling your data and gathering whatever insights you want out of it, we need to write your DataFrame to an html file. Most people are unfamiliar with this function of Pandas so here is some boilerplate code. The function player_info() just returns our DataFrame, the important part is the to_html method it calls on the DataFrame. This will create an html table of our DataFrame. We can then open a new file called "index.html" which we want to write ("w") to and then write our html table to it after adding a little bootstrap css.

```python
# Creates HTML File from player_info
def create_player_table(self):

    html = self.player_info().to_html(classes=["table", "table-striped"])

    # write html to file
    text_file = open("index.html", "w")
    text_file.write('<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">\n')
    text_file.write(html)
    text_file.close()
```

By now if you run this program you should have an html file created in your local directory where you can see your pandas DataFrame of your data. Already that's some really cool stuff! If done correctly, your index.html file should look something like this if created correctly.

![screenshot](/assets/images/blogimages/figs-10-08/player_rankings.png)

---

## Upload to AWS

Before we can programmatically upload our file to AWS and have it create a static website for us we need to do a few things and follow a simple tutorial. Make sure that you have an AWS account. The free tier is perfectly fine and an account is easy to create. When you have an account then follow the tutorial [here](https://docs.aws.amazon.com/AmazonS3/latest/userguide/HostingWebsiteOnS3Setup.html). When you get to step 5, we already have the index.html file we want to upload so use ours instead. Step 6 isn't super important so you can skip that one if you really want. After Step 7 you will be able to see your index.html file at a url that you can give anyone! Now that's amazing! The bottom of Step 7 provides instructions for creating a custom domain name such as the one I deployed my website to: [adamlenning.com](http://adamlenning.com)

Now that we have uploaded an initial version of our index.html file we can continue to manually upload that file everytime we run our python script and generate a new index.html file. Alternatively we can do that programmatically which is way more fun and saves you about 1 minute of work, something programmers always tout.

First we need to set up the AWS CLI so that we can access AWS from our command lines. Tutorial for getting that installed and set up can be found [here](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html). Make sure to configure your cli (tutorial found on the left side of the page).

Once we have that set up we can very simply upload an html file.

```python
import logging
import boto3
import boto3.session
from botocore.exceptions import ClientError

def upload_s3(file):

    session = boto3.session.Session(profile_name='default')
    s3_client = session.client('s3')

    try:
        s3_client.upload_file(Filename=file, Bucket="adamlenning.com", Key=file,  ExtraArgs={'ContentType': "text/html"})
    except ClientError as e:
        logging.error(e)
        return False
    return True

```

The important things to note are what profile_name you are using. This is the profile name you configured when you configured your cli. The other important part is the Bucket which tells the connection which bucket to upload it to. Put the name of the bucket your created during the tutorial in there. Once you have done that you can now call this function and pass the html file into it and it will automatically upload your index.html file to s3 which will continuosly host it on the website you found! Now that is some cool stuff!

This tutorial may have seemed long and there were many other tutorials to follow along the way, but at the end of the day (or days) that it takes you to accomplish this, you'll have a very nifty board game tracker where you only have to add data to the google sheet and then run the script and you'll see your new game stats immediately! Such a rewarding experience is really worth the effort!

Link to GitHub: [https://github.com/AdamLenning/sheets-catan](https://github.com/AdamLenning/sheets-catan)